<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>临水轩志</title>
    <link>http://yumminhuang.github.io/</link>
    <description>Recent content on 临水轩志</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 03 Dec 2015 21:12:18 -0500</lastBuildDate>
    <atom:link href="http://yumminhuang.github.io/index.xml" rel="self" type="application/rss+xml" />
    
      
    
      
    
      
    
      
        
          <item>
            <title>将博客由 Pelican 迁移到 Hugo</title>
            <link>http://yumminhuang.github.io/blog/2015/11/13/%E5%B0%86%E5%8D%9A%E5%AE%A2%E7%94%B1-pelican-%E8%BF%81%E7%A7%BB%E5%88%B0-hugo/</link>
            <pubDate>Fri, 13 Nov 2015 09:38:53 -0500</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/11/13/%E5%B0%86%E5%8D%9A%E5%AE%A2%E7%94%B1-pelican-%E8%BF%81%E7%A7%BB%E5%88%B0-hugo/</guid>
            <description>&lt;p&gt;前两天花了一些时间研究了一下 &lt;a href=&#34;https://gohugo.io/overview/introduction/&#34;&gt;Hugo 的文档&lt;/a&gt;，并且把博客从 &lt;a href=&#34;http://blog.getpelican.com/&#34;&gt;Pelican&lt;/a&gt; 迁移到 Hugo。
Pelican 是一个优秀的静态博客生成器。当初选用 Pelican 的主要是因为它是用 Python 开发的，而我又对 Python 比较熟悉。而且 Pelican 有很多由第三方开发者制作的插件提供了更多的功能。但是长期使用的过程中还是有一些小小的麻烦。当初，我想给博客里的中文文章添加&lt;a href=&#34;https://css.hanzi.co/&#34;&gt;「汉字标准格式」&lt;/a&gt; 这个框架，需要向模版里添加一段引入 CSS 和 JS 代码。但是 Pelican 的模版不易更改，我需要为了修改一两行 HTML 文件 Fork 之前的模版，方法既不优雅，维护成本又很高。另外，Pelican 的模版似乎是全局性的，所有的页面都使用相同的模版。&lt;/p&gt;

&lt;p&gt;后来，无意之间发现 Hugo 在配置和文件结构上和 Pelican 有很大的不同，大大地提高了可配置性，可以解决上述的两个问题。此外，第一次看到  &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo 官网&lt;/a&gt;的首页的时候，看上去非常漂亮，令人印象深刻。&lt;/p&gt;

&lt;p&gt;使用 &lt;code&gt;hugo new site SITE_DIR&lt;/code&gt; 新建一个 Hugo 之后，生成以下路径：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
├── archetypes/
├── config.toml
├── content/
├── data/
├── layouts/
└── static/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;config.toml&lt;/code&gt; 用来存放设置。&lt;code&gt;content/&lt;/code&gt; 里存放的是文章，&lt;code&gt;data/&lt;/code&gt; 用来存放一些数据。 &lt;code&gt;static/&lt;/code&gt; 里是需要引入的 CSS 或图片之类的文件。如果需要添加现场的主题模版，可以添加到 &lt;code&gt;themes/&lt;/code&gt; 里并在&lt;code&gt;config.toml&lt;/code&gt; 里设置。这些内容和 Pelican、Jekyll 一样，有的也可以望文生义，猜到大致的作用。&lt;/p&gt;

&lt;p&gt;加下来着重介绍的是 &lt;code&gt;layouts/&lt;/code&gt;，这里定义了博客的模版，是自定义 Hugo 最重要的部分。和 Pelican 有很大不同的地方是，Hugo 可以自定义文章的类型（ Type ）。不同的类型可以使用不同的模版。比如，除了第三方主题提供的文章类型，我还想为中文文章新建一个类型 &lt;code&gt;zhpost&lt;/code&gt;。只需要在 &lt;code&gt;layouts/&lt;/code&gt; 下新建一个 &lt;code&gt;zhpost/&lt;/code&gt;。接着，我可以设置中文文章的样式，只需新建一个 &lt;code&gt;single.html&lt;/code&gt; 就可以了。我也因此可以在&lt;code&gt;layouts/zhpost/single.html&lt;/code&gt; 里引入「汉字标准格式」的 CSS 和 JS。另外，对于第三方主题的模版不满意的话还可以按照相同的路径重写一个。Hugo 会优先读取根目录下 &lt;code&gt;layouts/&lt;/code&gt; 里的设置。具体来说，&lt;code&gt;layouts/post/single.html&lt;/code&gt; 可以覆盖 &lt;code&gt;themes/THEME/layouts/post/single.html&lt;/code&gt;。这样我就可以很容易的替换不满意的模版了。&lt;/p&gt;

&lt;p&gt;Hugo 的可定制性非常高，从 404 页面，到文章列表的页面都可以修改，而且可以做到不同类型的文章使用不一样的样式。具体的配置需要参考&lt;a href=&#34;http://themes.gohugo.io/&#34;&gt;第三方的主题&lt;/a&gt;的设置和 Hugo 的文档。&lt;/p&gt;

&lt;p&gt;值得一提的是，Go 的模版语言可读性很高，几乎不需要花额外的时间学习。我对照着别人开发的主题照葫芦画瓢就完成了模版的定义和修改。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;archetypes/&lt;/code&gt;，用来存放定义的「原型」。原型的作用是自动添加文字的元数据。比如，我想每次创建 &lt;code&gt;post&lt;/code&gt; 类文章的时候都自动添加元数据，只需要在 &lt;code&gt;archetypes/&lt;/code&gt; 里添加一个 &lt;code&gt;post.md&lt;/code&gt;，并加入以下内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+++
title = &amp;quot;my new post&amp;quot;
date = &amp;quot;2015-01-12T19:20:04-07:00&amp;quot;
tags = [&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;]
categories = [&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;]
+++
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样每次运行 &lt;code&gt;hugo new post/ARTICLE.md&lt;/code&gt; 的时候都可以自动添加上面的元数据。&lt;/p&gt;

&lt;p&gt;Hugo 另外的一个优点是生成博客的速度非常快，生成一个网页的速度可以达到毫秒级别。如果博客的内容很多，Hugo 要比 Pelican、Jekyll 等由动态语言写成的博客生成器有很大的优势。&lt;/p&gt;

&lt;p&gt;当然，Hugo 也有不足。比如，Hugo 默认是不支持代码高亮的，需要额外设置。此外，在 Pelican 里，可以通过 &lt;a href=&#34;https://github.com/yuex/cjk-auto-spacing&#34;&gt;cjk-auto-spacing&lt;/a&gt; 插件来自动在英文单词和汉字之间插入空格，这对于有大量中英文混排的技术笔记来说非常方便。但是，目前我还没有找到 Hugo 有类似的解决方法，暂时只能在写文章的时候手工加入空格。&lt;/p&gt;

&lt;p&gt;刚开始使用 Hugo，有一些诸如 Taxonomies，Section 之类的功能还没有仔细研究。这篇文章也是草草完成，不慎严谨，俟后完善。&lt;/p&gt;
</description>
          </item>
        
      
    
      
    
      
    
      
        
          <item>
            <title>Ruby 中的猴子补丁</title>
            <link>http://yumminhuang.github.io/blog/2015/06/27/ruby-%E4%B8%AD%E7%9A%84%E7%8C%B4%E5%AD%90%E8%A1%A5%E4%B8%81/</link>
            <pubDate>Sat, 27 Jun 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/06/27/ruby-%E4%B8%AD%E7%9A%84%E7%8C%B4%E5%AD%90%E8%A1%A5%E4%B8%81/</guid>
            <description>

&lt;p&gt;之前一段时间，在实习工作当中，使用到了一种有些独特的编程技巧；而且该技巧又有一个奇特的名称：「猴子补丁」。&lt;/p&gt;

&lt;h2 id=&#34;猴子补丁:aca85750c766d78d41bd1c15f9f6ff31&#34;&gt;猴子补丁&lt;/h2&gt;

&lt;p&gt;猴子补丁（&lt;a href=&#34;https://en.wikipedia.org/wiki/Monkey_patch&#34;&gt;Monkey Patch&lt;/a&gt;）是一种特殊的编程技巧。Monkey patch 可以用来在运行时动态地修改（扩展）类或模块。我们可以通过添加 Monkey Patch 来修改不满足自己需求的第三方库，也可以添加 Monkey Patch 零时修改代码中的错误。&lt;/p&gt;

&lt;h3 id=&#34;词源:aca85750c766d78d41bd1c15f9f6ff31&#34;&gt;词源&lt;/h3&gt;

&lt;p&gt;Monkey patch 最早被称作 Guerrilla patch，形容这种补丁像游击队员一样狡猾。后来因为发音相似，被称为 Gorilla patch。因为大猩猩不够可爱，后改称为 Monkey patch。&lt;/p&gt;

&lt;h3 id=&#34;使用场景:aca85750c766d78d41bd1c15f9f6ff31&#34;&gt;使用场景&lt;/h3&gt;

&lt;p&gt;以我的理解，Monkey patch 有两种使用场景：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;紧急的安全性补丁，即 Hotfix；&lt;/li&gt;
&lt;li&gt;修改或扩展库中的属性和方法。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;在-ruby-中使用-monkey-patch:aca85750c766d78d41bd1c15f9f6ff31&#34;&gt;在 Ruby 中使用 Monkey Patch&lt;/h2&gt;

&lt;p&gt;我当时遇到的场景是这样的：&lt;/p&gt;

&lt;p&gt;我司使用第三方库 &lt;a href=&#34;http://fog.io/&#34;&gt;fog&lt;/a&gt; 进行 EC2 的操作。创建实例等很多命令都需要设置实例类型这个参数。在 fog 里，EC2 的所有类型都定义在 &lt;code&gt;fog/aws/models/compute/flavors.rb&lt;/code&gt; 的 &lt;code&gt;FLAVORS&lt;/code&gt; 数组里。如果设置的类型不在 &lt;code&gt;FLAVORS&lt;/code&gt; 数组里，fog 都会视作是无效的参数而报错。&lt;/p&gt;

&lt;p&gt;后来，亚马逊发布了新的实例类型 &lt;code&gt;D2&lt;/code&gt;。虽然 Ruby 的第三方社区非常活跃，但是 fog 的开发社区还是没有及时添加 D2 到 &lt;code&gt;flavors.rb&lt;/code&gt; 里；而我司的工作又迫切需要使用 D2 类型的实例。&lt;/p&gt;

&lt;p&gt;背景交待完毕，接下来看看有什么样的解决方法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方法一&lt;/strong&gt;：我们可以向 fog 提交一个 Pull Request 来添加新类型。&lt;/p&gt;

&lt;p&gt;但是这个方法行不通。我们使用的 &lt;a href=&#34;https://github.com/chef/knife-ec2&#34;&gt;knife-ec2&lt;/a&gt; 对 fog 的版本依赖必须是 &lt;code&gt;1.25.*&lt;/code&gt;，但是 fog 已经更新到了 &lt;code&gt;1.31.0&lt;/code&gt;，而且 fog 从 &lt;code&gt;1.27.0&lt;/code&gt; 开始结构上有很大的变化。显然，我们不可能再等 knife-ec2 升级支持新版本的 fog，所以我们提交 Pull Request 更新 fog 不能解决问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方法二&lt;/strong&gt;：手动更新旧版 fog
既然不能使用最新版的 fog，我们可以手动编辑 &lt;code&gt;1.25&lt;/code&gt; 版的 fog，再打包成 Gem 使用。这个方法比前一个方法更容易操作，但是带来的问题时不易于维护。为了一个极小的改动，把自己的代码加入到第三方库中总是让人觉得不够「干净」。&lt;/p&gt;

&lt;p&gt;最后，在同事的指点下，我采用了第三种方法，即 &lt;strong&gt;Monkey Patch&lt;/strong&gt;。我在我司的 Ruby 项目里添加了一个文件 &lt;code&gt;lib/PROJECT_NAME/monkey_patches/flavors.rb&lt;/code&gt;，接着在文件中添加以下代码来修改 &lt;code&gt;fog/aws/models/compute/flavors&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;require &#39;fog/aws/models/compute/flavors&#39;

class Object

  def redef_without_warning(const, value)
    mod = self.is_a?(Module) ? self : self.class
    mod.send(:remove_const, const) if mod.const_defined?(const)
    mod.const_set(const, value)
  end
end

module Fog
  module Compute
    class AWS
      NEW_FLAVORS = FLAVORS + [
        {
          :id =&amp;gt; &amp;quot;d2.xlarge&amp;quot;,
          ...
        },
        {
          :id =&amp;gt; &amp;quot;d2.2xlarge&amp;quot;,
          ...
        },
        {
          :id =&amp;gt; &amp;quot;d2.4xlarge&amp;quot;,
          ...
        },
        {
          :id =&amp;gt; &amp;quot;d2.8xlarge&amp;quot;,
          ...
        }
      ]

      redef_without_warning :FLAVORS, NEW_FLAVORS

    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结:aca85750c766d78d41bd1c15f9f6ff31&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;通过在自己的代码中添加一个 Monkey patch，我们成功地实现了向 fog 中动态添加新实例类型。我司终于可以使用 fog 创建 D2 类型的机器了；而且这个方法改动的代码量最小，也更加容易维护。&lt;/p&gt;

&lt;p&gt;Monkey Patch 并非是完美的解决方法，它会引入一些&lt;a href=&#34;https://en.wikipedia.org/wiki/Monkey_patch#Pitfalls&#34;&gt;陷阱&lt;/a&gt;。所以这个技巧在软件工程领域还有一些争议。不过，我还是觉得 Monkey Patch 是一个不错的零时性解决方法。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;参考文章:aca85750c766d78d41bd1c15f9f6ff31&#34;&gt;参考文章&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.justinweiss.com/blog/2015/01/20/3-ways-to-monkey-patch-without-making-a-mess/&#34;&gt;3 Ways to Monkey-patch Without Making a Mess&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://devblog.avdi.org/2008/02/23/why-monkeypatching-is-destroying-ruby/&#34;&gt;Monkeypatching is Destroying Ruby&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>Travis CI</title>
            <link>http://yumminhuang.github.io/blog/2015/06/20/travis-ci/</link>
            <pubDate>Sat, 20 Jun 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/06/20/travis-ci/</guid>
            <description>

&lt;p&gt;本文将主要介绍如何使用 &lt;a href=&#34;https://travis-ci.org&#34;&gt;Travis CI&lt;/a&gt; 托管 Github 上的开源项目，从而实现自动化测试、部署。同时，还将介绍使用 &lt;a href=&#34;https://coveralls.io/&#34;&gt;Coveralls&lt;/a&gt; 来监测测试覆盖率。&lt;/p&gt;

&lt;h2 id=&#34;travis-ci:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;Travis CI&lt;/h2&gt;

&lt;p&gt;Travis CI 是一款 Web 端的 &lt;ruby&gt; 持续 &lt;rt&gt;Continuous&lt;/rt&gt;&lt;/ruby&gt; &lt;ruby&gt; 集成 &lt;rt&gt;Integration&lt;/rt&gt;&lt;/ruby&gt; 工具。&lt;/p&gt;

&lt;p&gt;Travis CI 采用 &lt;a href=&#34;https://en.wikipedia.org/wiki/Freemium&#34;&gt;「Freemium」&lt;/a&gt; 的模式：对 Github 上的开源项目免费，付费的话则可以托管私有项目。Github 上很多知名的开源项目都适用 Travis CI 来进行自动化测试。&lt;/p&gt;

&lt;p&gt;和 Jenkins 相比，Travis CI 要轻量很多。但是已经足以完成简单的自动化测试、部署。&lt;/p&gt;

&lt;h2 id=&#34;coveralls:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;Coveralls&lt;/h2&gt;

&lt;p&gt;Coveralls 用来显示代码覆盖率，从而可以让程序员及时了解代码质量。&lt;/p&gt;

&lt;p&gt;Coveralls 和 Travis CI 一样，仅对 Github 上的开源项目免费。Coveralls 支持包括 Travis CI、Jenkins 在内的绝大多数持续集成工具。&lt;/p&gt;

&lt;h2 id=&#34;样例:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;样例&lt;/h2&gt;

&lt;p&gt;接下来以 Python 项目为例，说明如何使用 Travis CI 和 Coveralls&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:583dfe1ccd5a6962c32f3c2bbdee5427:src&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:583dfe1ccd5a6962c32f3c2bbdee5427:src&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h3 id=&#34;依赖管理和虚拟环境:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;依赖管理和虚拟环境&lt;/h3&gt;

&lt;p&gt;我喜欢为每个项目新建一个 &lt;ruby&gt;virtualenv&lt;rt&gt; 虚拟环境 &lt;/rt&gt;&lt;/ruby&gt;，这样可以确保每个项目的开发环境相互独立，避免发生冲突。&lt;a href=&#34;https://virtualenvwrapper.readthedocs.org/en/latest/&#34;&gt;virtualenvwrapper&lt;/a&gt; 是一个让人方便使用 virtualenv 的小工具。它把如新建 virtualenv、切换 virtualenv 等常用的操作都封装成了简单的指令。&lt;/p&gt;

&lt;p&gt;我一般会在项目中添加一个 &lt;code&gt;requirements.txt&lt;/code&gt;，里面列出项目所依赖的 Pip 库。这样在 virtualenv 中，直接运行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;:::bash
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以安装所有的库。&lt;/p&gt;

&lt;h3 id=&#34;单元测试和测试覆盖:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;单元测试和测试覆盖&lt;/h3&gt;

&lt;p&gt;对于 Python 项目，我喜欢使用 &lt;a href=&#34;https://nose.readthedocs.org/en/latest/&#34;&gt;nose&lt;/a&gt; 来进行单元测试。此外，我还会使用 &lt;a href=&#34;http://nedbatchelder.com/code/coverage/&#34;&gt;coverage.py&lt;/a&gt; 来测量代码的测试覆盖率。&lt;/p&gt;

&lt;p&gt;nose 对 coverage.py 的支持非常好，可以在 &lt;code&gt;nosetests&lt;/code&gt; 命令后添加一系列选项来生成覆盖率。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;:::bash
nosetests --with-coverage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以直接得到测试覆盖率的数据。&lt;/p&gt;

&lt;p&gt;详细的使用方法可以参见 &lt;a href=&#34;https://nose.readthedocs.org/en/latest/&#34;&gt;nose 的官方文档&lt;/a&gt; 和&lt;a href=&#34;http://nedbatchelder.com/code/coverage/cmd.html&#34;&gt;coverage.py 的官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;持续集成:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;持续集成&lt;/h3&gt;

&lt;p&gt;在 Github 上新建项目之后，在 Travis CI 的页面上开启该项目。（新建的项目可能不会及时出现在 Travis CI 页面上，需要手动同步一下 Github 的项目。）接着，在 Github 项目里添加 Travis CI 的配置文件 &lt;code&gt;.travis.yml&lt;/code&gt;。Travis CI 的配置使用的是非常易读的 YAML 文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;:::yaml
language: python
python:
    - 2.6
    - 2.7
# command to install dependencies
install:
    - pip install -r requirements.txt
    - pip install coveralls
# command to run tests
script:
    nosetests --cover-package=project --with-coverage
# coveralls
after_success:
    coveralls
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样地，也需要在 Coveralls 上开启相应的项目。&lt;/p&gt;

&lt;p&gt;这样，Github 的代码库在每次收到 &lt;code&gt;Push&lt;/code&gt; 和 &lt;code&gt;Pull Request&lt;/code&gt; 的时候，Travis CI 都会按照配置文件上的步骤自动运行测试（或者部署，本样例只有测试。），并且把测试覆盖率的数据发布到 Coveralls。&lt;/p&gt;

&lt;p&gt;详细的配置说明可以参见 &lt;a href=&#34;http://docs.travis-ci.com/&#34;&gt;Travis CI 的官方文档&lt;/a&gt; 和&lt;a href=&#34;https://coveralls.zendesk.com/hc/en-us&#34;&gt;Coveralls 的官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;其它:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;其它&lt;/h3&gt;

&lt;p&gt;Travis CI 和 Coveralls 都可以生成 &lt;ruby&gt; 图章 &lt;rt&gt;Badge&lt;/rt&gt;&lt;/ruby&gt;，用来显示 &lt;ruby&gt; 构建 &lt;rt&gt;Build&lt;/rt&gt;&lt;/ruby&gt; 的结果，或者测试覆盖率。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/yumminhuang/turbo-octo-meme&#34;&gt;&lt;img src=&#34;https://travis-ci.org/yumminhuang/turbo-octo-meme.svg?branch=master&#34; alt=&#34;Build Status&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以将这些图章（如果已经发布到 PyPi，还可以加上版本号、下载量的图章。）放在项目的 &lt;em&gt;README&lt;/em&gt; 文件里。&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:583dfe1ccd5a6962c32f3c2bbdee5427:src&#34;&gt;详细代码可参见 &lt;a href=&#34;https://github.com/yumminhuang/turbo-octo-meme&#34;&gt;turbo-octo-meme&lt;/a&gt;。
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:583dfe1ccd5a6962c32f3c2bbdee5427:src&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>Jenkins 简介</title>
            <link>http://yumminhuang.github.io/blog/2015/06/02/jenkins-%E7%AE%80%E4%BB%8B/</link>
            <pubDate>Tue, 02 Jun 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/06/02/jenkins-%E7%AE%80%E4%BB%8B/</guid>
            <description>

&lt;p&gt;在&lt;a href=&#34;http://yumminhuang.github.io/ji-yu-jenkinsde-pythondai-ma-ji-cheng-zheng-he.html&#34;&gt;之前的一篇文章中&lt;/a&gt;，曾经提及过 Jenkins。在本次实习中，Jenkins 是我每天都要使用的工具。在频繁的使用过程当中：通过实际工作感受了「持续集成」的概念（关于持续集成的概念，此处按下不表，待有时间的时候再详细总结。）；逐渐熟悉了 Jenkins 的使用，并且体会到其带来的方便。因此，希望总结一下 Jenkins 的使用。&lt;/p&gt;

&lt;p&gt;然而 Jenkins 不通过具体的案例难以体会其方便之处，网上相关使用说明之类的文章又颇多，所以本文仅谈个人使用中的体会，并非学习Jenkins使用的教程。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;jenkins是什么:e83bca251359d2ad1ae1277c1018011a&#34;&gt;Jenkins是什么&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://jenkins-ci.org/&#34;&gt;Jenkins&lt;/a&gt; 是一个用 Java 编写的开源的&lt;ruby&gt;持续&lt;rt&gt;Continuous&lt;/rt&gt;&lt;/ruby&gt; &lt;ruby&gt;集成&lt;rt&gt;Integration&lt;/rt&gt;&lt;/ruby&gt;工具。&lt;/p&gt;

&lt;p&gt;Jenkins 是用 Java 开发的（界面和 Eclipse一样，带着一股浓浓的 SWT 的味道，好在界面并不太影响使用。），对 Java 程序开发有天然的良好支持，如 JUnit/TestNG 测试，Maven、Ant 等 Java 开发中常用的工具都包含在 Jenkins 里。当然，Jenkins 也可以通过插件来实现其它语言的开发。&lt;/p&gt;

&lt;h3 id=&#34;jenkins的特性:e83bca251359d2ad1ae1277c1018011a&#34;&gt;Jenkins的特性&lt;/h3&gt;

&lt;p&gt;在使用的过程中，我体会比较深刻的特性有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;项目易于配置&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在 Jenkins 当中，我们可以新建 Job。在 Job 里，可以设置添加&lt;ruby&gt;构建脚本&lt;rt&gt;Build Script&lt;/rt&gt;&lt;/ruby&gt;。构建脚本支持 Bash、Ant、Makefile；Job 的参数、&lt;ruby&gt;元&lt;rt&gt;Meta&lt;/rt&gt;&lt;/ruby&gt;数据可以作为环境变量在脚本里直接使用，因此设置起来非常方便。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;种类繁多的插件&lt;/strong&gt;（这点也和 Eclipse 也颇为相似）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Jenkins 的开发者社区非常活跃，&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Plugins&#34;&gt;第三方插件&lt;/a&gt;很多，从而可以帮助我们实现很多常用的功能。
比如，Hipchat 插件可以在 Job 运行结束后把结果发送到 Hipchat 的聊天室里；Cobertura 插件可以显示测试覆盖率的数据。&lt;/p&gt;

&lt;h3 id=&#34;jenkins的使用场景:e83bca251359d2ad1ae1277c1018011a&#34;&gt;Jenkins的使用场景&lt;/h3&gt;

&lt;p&gt;在我们公司，Jenkins 主要被用来用于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;ruby&gt;构建&lt;rt&gt;Build&lt;/rt&gt;&lt;/ruby&gt;、&lt;ruby&gt;测试&lt;rt&gt;Test&lt;/rt&gt;&lt;/ruby&gt;、&lt;ruby&gt;部署&lt;rt&gt;Deploy&lt;/rt&gt;&lt;/ruby&gt;代码&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们可以通过一个 Job 实现以下流程：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;使用 Git 插件，从代码库下载任一版本或分支的源代码；&lt;/li&gt;
&lt;li&gt;编译代码；&lt;/li&gt;
&lt;li&gt;运行测试。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;或者是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;启动若干个 EC2 实例；&lt;/li&gt;
&lt;li&gt;将任一版本的代码部署到新建的实例上。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;所有的这些流程在 Jenkins 里，都只需要设置几个简单的参数（如分支的名称，或者是实例的个数），再点击运行按钮就可以了。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;自动化一些复杂的流程，如数据库的迁移、备份，系统更新的安装等等&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有一些常用，但是流程很复杂的过程，可以在 Jenkins 里通过 Job 来完成。&lt;/p&gt;
</description>
          </item>
        
      
    
      
    
      
        
          <item>
            <title>基于 Jenkins 的 Python 代码集成整合</title>
            <link>http://yumminhuang.github.io/blog/2015/04/17/%E5%9F%BA%E4%BA%8E-jenkins-%E7%9A%84-python-%E4%BB%A3%E7%A0%81%E9%9B%86%E6%88%90%E6%95%B4%E5%90%88/</link>
            <pubDate>Fri, 17 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/17/%E5%9F%BA%E4%BA%8E-jenkins-%E7%9A%84-python-%E4%BB%A3%E7%A0%81%E9%9B%86%E6%88%90%E6%95%B4%E5%90%88/</guid>
            <description>

&lt;p&gt;实习中最近做了一个多月的项目是将代码测试覆盖率整合到公司持续整合（Continuous Integration）的流程当中。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This project uses Java and XML. How it could be good?&lt;/p&gt;

&lt;p&gt;——组里的同事如此评价本项目&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;本文介绍该项目的大致流程，共分为两部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;介绍 * Automated python unit testing, code coverage and code quality analysis with Jenkins*（&lt;a href=&#34;http://bhfsteve.blogspot.com/2012/04/automated-python-unit-testing-code.html&#34;&gt;part1&lt;/a&gt;, &lt;a href=&#34;http://bhfsteve.blogspot.com/2012/04/automated-python-unit-testing-code_20.html&#34;&gt;part2&lt;/a&gt;, &lt;a href=&#34;http://bhfsteve.blogspot.com/2012/04/automated-python-unit-testing-code_27.html&#34;&gt;part3&lt;/a&gt;）中使用 Jenkins 实现自动化测试、得到代码覆盖率和代码质量的方法。&lt;/li&gt;
&lt;li&gt;简要介绍我们如何在这篇文章的基础上把代码覆盖率整合到公司的 Bitbucket 代码库当中。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;基于-jenkins-的-python-自动化测试工具:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;基于 Jenkins 的 Python 自动化测试工具&lt;/h3&gt;

&lt;p&gt;使用到的 Python 模块：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nedbatchelder.com/code/coverage/&#34;&gt;coverage&lt;/a&gt;：用来生成代码覆盖率的数据；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nose.readthedocs.org/en/latest/&#34;&gt;nose&lt;/a&gt;: 用来运行单元测试；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pylint.org&#34;&gt;pylint&lt;/a&gt;：用来得到 Python 代码质量的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用到的 Jenkins 插件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Cobertura+Plugin&#34;&gt;Cobertura plugin&lt;/a&gt;：用来显示代码覆盖率；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Git+Plugin&#34;&gt;GIT plugin&lt;/a&gt;：用来获取最新的代码；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Violations&#34;&gt;Violations plugin&lt;/a&gt;：用来显示 pylint 的结果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;安装需要的 Jenkins 插件之后，在 Jenkins 当中新建一个作业（Job）接下来进行设置。&lt;/p&gt;

&lt;h4 id=&#34;从哪里得到代码:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;从哪里得到代码&lt;/h4&gt;

&lt;p&gt;如下图所以，在 Jenkins 的 &lt;strong&gt;Source Code Management&lt;/strong&gt; 当中可以添加 Git Repository。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://2.bp.blogspot.com/-hDwb_sbJZHk/T5lzDbCT76I/AAAAAAAAADg/adELp3TAeV8/s1600/Source+code.png&#34; alt=&#34;SCM&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Jenkins 同样支持 subversion 等 CVS 工具。&lt;/p&gt;

&lt;h4 id=&#34;什么时候运行作业:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;什么时候运行作业&lt;/h4&gt;

&lt;p&gt;在 Jenkins 中可以将 &lt;strong&gt;Build Triggers&lt;/strong&gt; 设置为 &lt;strong&gt;Poll SCM&lt;/strong&gt; 对代码库进行轮询。如下图，&lt;strong&gt;Schedule&lt;/strong&gt; 设为 &lt;code&gt;* * * * *&lt;/code&gt;（含义和 Cron 一样）表示每分钟检查一次代码库，看是否有更新。如果代码库有更新的话则运行 &lt;strong&gt;Build&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://3.bp.blogspot.com/-DewpmzsyWZo/T5lzXqPVOlI/AAAAAAAAADo/OA2Fxd1YTzY/s1600/Build+triggers.png&#34; alt=&#34;Poll SCM&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当然，也可以使用 &lt;a href=&#34;http://git-scm.com/book/zh/v2/Customizing-Git-Git-Hooks&#34;&gt;Git Hook&lt;/a&gt;，从而避免轮询消耗过多的资源。&lt;/p&gt;

&lt;h4 id=&#34;运行什么:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;运行什么&lt;/h4&gt;

&lt;p&gt;添加一段 &lt;strong&gt;Build Script&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PYTHONPATH=&#39;&#39;
nosetests --with-xunit --all-modules --traverse-namespace --with-coverage --cover-package=project1 --cover-inclusive
python -m coverage xml --include=project1*
pylint -f parseable -d I0011,R0801 project1 | tee pylint.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这段 Shell 脚本中的三个命令：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;nosetests&lt;/code&gt; 命令运行单元测试；&lt;/li&gt;
&lt;li&gt;运行 &lt;code&gt;coverage&lt;/code&gt;，将覆盖率数据输出为 xml 文件；&lt;/li&gt;
&lt;li&gt;运行 &lt;code&gt;pylint&lt;/code&gt; 得到代码的质量数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;具体参数的含义可以参阅原文的第一、第二部分。&lt;/p&gt;

&lt;h4 id=&#34;显示结果:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;显示结果&lt;/h4&gt;

&lt;p&gt;上一步的 Build Script 有三个输出文件：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;nosetests.xml&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;coverage.xml&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pylint.out&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接着，在 Jenkins 当中，在 &lt;strong&gt;Publish JUnit test result report&lt;/strong&gt; 添加 &lt;code&gt;nosetests.xml&lt;/code&gt; 显示单元测试的结果。在 Cobertura 插件 &lt;strong&gt;Publish Cobertura Coverage Report&lt;/strong&gt; 里添加 &lt;code&gt;coverage.xml&lt;/code&gt; 显示测试代码覆盖率。在 &lt;strong&gt;Report Violations&lt;/strong&gt; 里添加 &lt;code&gt;pylint.out&lt;/code&gt; 显示代码质量报告。&lt;/p&gt;

&lt;p&gt;最终，运行一次作业之后，Jenkins 将可以得到下图显示的测试报告。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://4.bp.blogspot.com/-f_YtJcTOQ64/T5qnlOiE35I/AAAAAAAAAF8/l5Nl_YvRSuM/s1600/jenkins+after+logout+added.png&#34; alt=&#34;Jenkins Output&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;持续整合:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;持续整合！&lt;/h3&gt;

&lt;p&gt;我们持续整合的大致流程是这样的。在代码库中有一个 Master 分支，开发人员添加新功能，修复 Bug 都需要在新建的分支里进行。每新建一个合并到到 Master 的 Pull Request 时，Jenkins 可以自动运行测试。测试通过则在 Bitbucket 的 Pull Request 页面里添加一个的评论表示可以合并，否则会添加一个否决的评论。这个项目的目标就是再添加一个关于测试覆盖率的评论。&lt;/p&gt;

&lt;p&gt;我们按照 &lt;em&gt;Automated python unit testing, code coverage and code quality analysis with Jenkins&lt;/em&gt; 一文的思路实现了测试覆盖率的部分，区别是我们的代码库里包括 Java 和 Python 两种语言的代码，需要同时处理两份数据。经过一段时间的攻关之后，我们终于可以得到代码覆盖的数据。&lt;/p&gt;

&lt;p&gt;相较于测试覆盖率的具体数值，我们更关心覆盖率的变化值。我们希望知道合并一个分支之后，测试覆盖率是增加了还是减少了。因此，现在我们需要得到测试覆盖率的变化值（Coverage diff）。&lt;/p&gt;

&lt;p&gt;没想到 Python 连这种冷僻的使用场景都有第三方的库支持，还不只一个。我们使用的是 &lt;a href=&#34;https://github.com/SurveyMonkey/pycobertura&#34;&gt;Pycobertura&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Pycobertura 可以直接比较两个 Cobertura 格式的 xml 文件，从而得到覆盖率的变化值。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from pycobertura import Cobertura
from pycobertura import TextReporterDelta

coverage1 = Cobertura(&#39;coverage1.xml&#39;)
coverage2 = Cobertura(&#39;coverage2.xml&#39;)
delta = TextReporterDelta(coverage1, coverage2)
delta.generate()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;于是，我创建了一个 Fabric Task，调用 Pycobertura 分析测试生成的 xml 文件和 Master branch 的 xml 文件。在 Jenkins 里添加一段 &lt;strong&gt;Post build script&lt;/strong&gt; 来运行 Fabric，这样 Build 完成之后就可以运行 Fabric 程序得到类似下面的输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Coverage Diff for Java code:
No coverage diff can be found.
Coverage Diff for Python code:
Name          Stmts    Miss    Cover
------------  -------  ------  --------
dummy/dummy   -        -2      +50.00%
dummy/dummy2  +2       -       +100.00%
TOTAL         +2       -2      +50.00%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后剩下的就是把之前一步的结果以评论的形式发布到 Bitbucket 里。这里，我们又添加了一个 Fabric 的 Task，通过调用 Bitbucket 的 API 把得到的结果发布到 Pull Request 的页面里。&lt;/p&gt;

&lt;h3 id=&#34;参考文献:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;参考文献&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://bhfsteve.blogspot.com/2012/04/automated-python-unit-testing-code_27.html&#34;&gt;Automated python unit testing, code coverage and code quality analysis with Jenkins - part 3&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>使用 Fabric 进行远程操作</title>
            <link>http://yumminhuang.github.io/blog/2015/04/16/%E4%BD%BF%E7%94%A8-fabric-%E8%BF%9B%E8%A1%8C%E8%BF%9C%E7%A8%8B%E6%93%8D%E4%BD%9C/</link>
            <pubDate>Thu, 16 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/16/%E4%BD%BF%E7%94%A8-fabric-%E8%BF%9B%E8%A1%8C%E8%BF%9C%E7%A8%8B%E6%93%8D%E4%BD%9C/</guid>
            <description>

&lt;h2 id=&#34;fabric-简介:900de048502f7d5abcf000aa59dbd264&#34;&gt;Fabric 简介&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.fabfile.org&#34;&gt;Fabric&lt;/a&gt; 是一个实现远程操作和部署的 Python 模块。Fabric 主要用来作为 SSH 的替代，实现一些简单的应用部署和系统管理。&lt;/p&gt;

&lt;h3 id=&#34;使用-fabric-的好处:900de048502f7d5abcf000aa59dbd264&#34;&gt;使用 Fabric 的好处&lt;/h3&gt;

&lt;p&gt;个人觉得，Fabric 非常适合简单的、重复性的远程操作。&lt;/p&gt;

&lt;p&gt;首先，Fabric 可以使用 Python，比 Shell 要强大、灵活。&lt;/p&gt;

&lt;p&gt;再者，Fabric 避免远程登录，可以把远程操作放在本地运行。&lt;/p&gt;

&lt;p&gt;最后，Fabric 非常简单，只需要编写一个 &lt;code&gt;fabfile.py&lt;/code&gt;（或者像 Python 那样 &lt;a href=&#34;http://docs.fabfile.org/en/latest/usage/fabfiles.html&#34;&gt;导入包来添加更多的功能&lt;/a&gt;），就可以使用&lt;a href=&#34;http://docs.fabfile.org/en/latest/usage/fab.html&#34;&gt;&lt;code&gt;fab&lt;/code&gt; 指令&lt;/a&gt; 运行了。这比 Salt、Chef 等工具轻量，更加容易上手。&lt;/p&gt;

&lt;p&gt;基本上，代码部署，文件修改，远程执行等操作都可以使用 Fabric。&lt;/p&gt;

&lt;h2 id=&#34;常用的-fabric-函数:900de048502f7d5abcf000aa59dbd264&#34;&gt;常用的 Fabric 函数&lt;/h2&gt;

&lt;p&gt;这里简单地介绍 Fabric 里常用的函数，具体的说明请参见 &lt;a href=&#34;http://docs.fabfile.org/en/latest/index.html&#34;&gt;官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;常用操作:900de048502f7d5abcf000aa59dbd264&#34;&gt;常用操作&lt;/h2&gt;

&lt;p&gt;Fabric 的常用 &lt;a href=&#34;http://docs.fabfile.org/en/latest/api/core/operations.html&#34;&gt;操作&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;run&lt;/code&gt;：在远程机器上执行 Shell 命令；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo&lt;/code&gt;：带有 root 权限的 &lt;code&gt;run&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;local&lt;/code&gt;：执行本地命令；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get&lt;/code&gt;：从远程机器下载文件；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;put&lt;/code&gt;：上传文件到远程机器；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prompt&lt;/code&gt;：可以理解为在远程机器上执行 &lt;code&gt;raw_input&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reboot&lt;/code&gt;：重启远程机器。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;常用上下文管理器和装饰器:900de048502f7d5abcf000aa59dbd264&#34;&gt;常用上下文管理器和装饰器&lt;/h3&gt;

&lt;p&gt;上下文管理器（Context Manager）和装饰器（Decorators）是 Python 中的常用的 &lt;a href=&#34;http://zh.wikipedia.org/wiki / 语法糖&#34;&gt;「语法糖（Syntax sugar）」&lt;/a&gt;。Fabric 中常用的&lt;a href=&#34;http://docs.fabfile.org/en/latest/api/core/context_managers.html&#34;&gt;上下文管理器&lt;/a&gt; 有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cd&lt;/code&gt;：切换目录；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lcd&lt;/code&gt;：在本地切换目录，即 &lt;code&gt;local cd&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;path&lt;/code&gt;：可以添加路径到 &lt;code&gt;PATH&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;settings&lt;/code&gt;：用来临时修改 &lt;code&gt;env&lt;/code&gt; 变量，使变量只作用在一段代码中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;常用的 &lt;a href=&#34;http://docs.fabfile.org/en/latest/api/core/decorators.html&#34;&gt;装饰器&lt;/a&gt; 有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@task&lt;/code&gt;：用来把一个函数声明为 &lt;a href=&#34;http://docs.fabfile.org/en/latest/usage/tasks.html&#34;&gt;Fabric Task&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@hosts&lt;/code&gt;：用来制定远程操作的目标机器；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@with_settings&lt;/code&gt;：用来临时设定 &lt;code&gt;env&lt;/code&gt; 变量，可以等同于 &lt;code&gt;with settings&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fabric Task 是我个人非常喜欢的功能。定义一个 Task 之后就可以直接使用 &lt;code&gt;fab task_name&lt;/code&gt; 来执行了。&lt;/p&gt;

&lt;h2 id=&#34;一个例子:900de048502f7d5abcf000aa59dbd264&#34;&gt;一个例子&lt;/h2&gt;

&lt;p&gt;在实习当中，我做了一个工具用来自动备份 AWS EBS Volume。程序运行在远程服务器上。每天早上，我都要检查一下日志文件，看看程序有没有出错。&lt;/p&gt;

&lt;p&gt;开始，我检查的方式是使用 &lt;code&gt;ssh&lt;/code&gt; 登陆之后，再使用 &lt;code&gt;grep&lt;/code&gt; 检查日志文件是否包含 &lt;code&gt;ERROR&lt;/code&gt;、&lt;code&gt;WARNING&lt;/code&gt; 等关键字。后来，我发现检查日志文件的操作都是一些重复操作，于是就写了一个 Bash 脚本来进行检查。这样，每天检查的过程就是使用 &lt;code&gt;ssh&lt;/code&gt; 登陆，再运行脚本进行检查。&lt;/p&gt;

&lt;p&gt;但是，这样检查日志还是有一些麻烦，这促使我转而使用 Fabric。第一，每天都需要远程登录。使用 Fabric 可以直接在本地运行。第二，因为日志每天晚上会回滚，我不仅要检查当天的日志文件，还要检查昨天的日志来确保昨天下班之后程序没有出问题，而日志的名称会随着日期变化。在 Bash 里计算日期是一件相当麻烦的事情。但是，使用 Fabric 之后，因为可以利用 Python 的 &lt;code&gt;datetime&lt;/code&gt;，计算日期就变得非常容易了。下面就是用来检查日志是否包含关键字的函数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from fabric.api import *

def check_log_with_keyword(log_file, keyword):
    with settings(hide(&#39;warnings&#39;,&#39;output&#39;),
                  host_string=&#39;eb101.ops&#39;,
                  warn_only=True):
        result = run(&#39;grep %s %s&#39; % (keyword, filename))

        if result.return_code == 0:
            print(result)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;with settings()&lt;/code&gt; 来临时更改 &lt;code&gt;env&lt;/code&gt; 变量；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hide(&#39;warnings&#39;, &#39;output&#39;)&lt;/code&gt; 可以设置 Fabric 输出（不是远程执行的指令的输出），隐藏 &lt;code&gt;stderr&lt;/code&gt; 和 &lt;code&gt;stdout&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host_string=&#39;eb101.ops&#39;&lt;/code&gt;，设定目标机器，Fabric 可以使用 &lt;code&gt;.ssh/config&lt;/code&gt; 的设置；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;warn_only=True&lt;/code&gt; 用来确保 Fabric 程序不会因为 &lt;code&gt;grep&lt;/code&gt; 指令出错而退出（grep 没找到匹配内容时，返回值是 1）；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;result = run(&#39;grep %s %s&#39; % (keyword, filename))&lt;/code&gt;, 运行 &lt;code&gt;grep&lt;/code&gt; 指令并得到结果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;远程检查日志的过程很简单，并且是机械而重复的过程，因此非常适合使用 Fabric。&lt;/p&gt;

&lt;h3 id=&#34;参考文献:900de048502f7d5abcf000aa59dbd264&#34;&gt;参考文献&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-use-fabric-to-automate-administration-tasks-and-deployments&#34;&gt;How To Use Fabric To Automate Administration Tasks And Deployments&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>Graphite 和 Grafana 简介</title>
            <link>http://yumminhuang.github.io/blog/2015/04/08/graphite-%E5%92%8C-grafana-%E7%AE%80%E4%BB%8B/</link>
            <pubDate>Wed, 08 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/08/graphite-%E5%92%8C-grafana-%E7%AE%80%E4%BB%8B/</guid>
            <description>

&lt;h2 id=&#34;graphite:b7837abce316965fc5b3c43248c541ea&#34;&gt;Graphite&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://graphite.wikidot.com/start&#34;&gt;Graphite&lt;/a&gt; 是一款开源的监控绘图工具。&lt;/p&gt;

&lt;p&gt;Graphite 可以实时收集、存储、显示时间序列类型的数据（time series data）。它主要有三个部分构成：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/graphite-project/carbon&#34;&gt;carbon&lt;/a&gt;&lt;/strong&gt; —— 基于 &lt;a href=&#34;https://twistedmatrix.com/trac/&#34;&gt;Twisted&lt;/a&gt; 的进程，用来接收数据；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/graphite-project/whisper&#34;&gt;whisper&lt;/a&gt;&lt;/strong&gt; —— 专门存储时间序列类型数据的小型数据库；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/graphite-project/graphite-web&#34;&gt;graphite webapp&lt;/a&gt;&lt;/strong&gt; —— 基于 Django 的网页应用程序。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/graphite-project/graphite-web/master/webapp/content/img/overview.png&#34; alt=&#34;Graphite Overview&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;向graphite发送数据:b7837abce316965fc5b3c43248c541ea&#34;&gt;向Graphite发送数据&lt;/h3&gt;

&lt;p&gt;Graphite 的使用非常简单。我们可以定义一个被观测量（Metric）。Metric 使用键／值的数据类型。只要不断发送&lt;code&gt;观测量: 观测值&lt;/code&gt;这一键值组合，就可以得到以时间为X轴，观测值为 Y 轴的图。&lt;/p&gt;

&lt;p&gt;当我们使用诸如 collectd、Sensu 之类的工具收集到数据之后，只需要向 Graphite 的服务器发送以下格式的 TCP 报文即可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;metric name&amp;gt; &amp;lt;metric value&amp;gt; &amp;lt;metric timestamp&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如，有一个 Metric 叫作 &lt;code&gt;local.metric.random&lt;/code&gt;，可以用下面的 Bash 命令发送当前时刻的值 &lt;code&gt;4&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PORT=2003
SERVER=graphite.your.org
echo &amp;quot;local.metric.random 4 `date +%s`&amp;quot; | nc -q0 ${SERVER} ${PORT}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;类似地，使用其它编程语言时，可以使用 Socket 发送数据。&lt;/p&gt;

&lt;p&gt;另外，Graphite 的 Metric 名称支持以 &lt;code&gt;.&lt;/code&gt; 作为分隔符的多级嵌套。例如我可以定义下面三个 Metric。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;webserver.system.cpu_usage&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;webserver.system.mem_load&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;webserver.network.input&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Graphite 将以树型结构展示这三个 Metric。因此，使用 Graphite 的第一步就是给 Metric 选取一个合适的名称。关于如何组织 Metric 的名称，可以参阅文章 &lt;a href=&#34;http://matt.aimonetti.net/posts/2013/06/26/practical-guide-to-graphite-monitoring/&#34;&gt;Practical Guide to StatsD/Graphite Monitoring&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;graphite-event:b7837abce316965fc5b3c43248c541ea&#34;&gt;Graphite Event&lt;/h3&gt;

&lt;p&gt;除了支持简单的键／值数据类型，Graphite 还可以通过 &lt;a href=&#34;http://graphite.readthedocs.org/en/1.0/functions.html#graphite.render.functions.events&#34;&gt;Events&lt;/a&gt; 来存储更复杂的数据。简而言之，Graphite Events 使用了 &lt;code&gt;tag&lt;/code&gt; 和 &lt;code&gt;data&lt;/code&gt; 两个键来存储更多的信息。&lt;/p&gt;

&lt;p&gt;我们可以使用 HTTP POST 向 Graphite 发送一个 Event。&lt;/p&gt;

&lt;p&gt;```curl -X POST &amp;ldquo;&lt;a href=&#34;http://graphite.your.org/events&amp;quot;&#34;&gt;http://graphite.your.org/events&amp;quot;&lt;/a&gt; -d &amp;lsquo;{&amp;ldquo;what&amp;rdquo;: &amp;ldquo;Deployment&amp;rdquo;, &amp;ldquo;tags&amp;rdquo;: &amp;ldquo;webserver&amp;rdquo;, &amp;ldquo;data&amp;rdquo;: &amp;ldquo;Deploy webserver&amp;rdquo;}&amp;rsquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
下文将会通过一个具体的实例来介绍Events的使用场景。

## Grafana

鉴于 Graphite 的界面过于简单，功能比较单一，可以使用 [Grafana](http://grafana.org/) 作为 Graphite 的控制台。 Grafana 是一款开源的图形控制台，有很多[不错的特性](http://grafana.org/features)，还可以访问官网提供的 [Live Demo](http://play.grafana.org) 来体验 Grafana。

设置 Grafana，只需编辑 `config.js` 设置数据来源[^update]。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;datasources: {
  graphite: {
    type: &amp;lsquo;graphite&amp;rsquo;,
    url: &amp;ldquo;&lt;a href=&#34;http://my.graphite.server.com:8080&amp;quot;&#34;&gt;http://my.graphite.server.com:8080&amp;quot;&lt;/a&gt;,
  }
},&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
具体的配置教程可以参见[官方文档](http://docs.grafana.org/v1.9/installation/)。

## 实例

我实习所在公司使用 [Jenkins](https://jenkins-ci.org) 部署代码。在部署完成之后，我添加了一段 [post-build script](https://wiki.jenkins-ci.org/display/JENKINS/PostBuildScript+Plugin) 执行下面的脚本。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#!/bin/bash&lt;/p&gt;

&lt;p&gt;HOST=&lt;a href=&#34;http://graphite.your.org/events&#34;&gt;http://graphite.your.org/events&lt;/a&gt;
echo &amp;lsquo;Posting a deployment event to Graphite&amp;rsquo;
curl -X POST $HOST -d &amp;lsquo;{&amp;ldquo;what&amp;rdquo;: &amp;ldquo;Deployment&amp;rdquo;, &amp;ldquo;tags&amp;rdquo;: &amp;ldquo;webserver,prd&amp;rdquo;, &amp;ldquo;data&amp;rdquo;: \&amp;ldquo;$BUILD_URL\&amp;ldquo;}&amp;rsquo;
```&lt;/p&gt;

&lt;p&gt;这样，每次部署完成之后都会发送一个 Deployment Event 到 Graphite。接着，可以在 Graphite 里添加 &lt;code&gt;drawAsInfinite(events(&#39;prd&#39;))&lt;/code&gt; 或者在 Grafana 里使用 &lt;a href=&#34;http://grafana.org/docs/features/annotations/&#34;&gt;Annotations Page&lt;/a&gt; 来绘制一幅图显示代码部署的 Events。&lt;/p&gt;

&lt;p&gt;利用 Graphite Events 和 Metrics，我们可以将代码部署和其他指征叠加在一幅图里，从而分析每次代码部署和其它指征的关系。&lt;/p&gt;

&lt;p&gt;比如，在 &lt;em&gt;Tracking Every Release&lt;/em&gt; 一文中，作者使用了该方法将 &lt;code&gt;PHP Warning&lt;/code&gt; 和 &lt;code&gt;Code deploy&lt;/code&gt; 叠加在一幅图里。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://codeascraft.com/wp-content/uploads/2010/12/warnings_1hr_deploys3.png&#34; alt=&#34;Track Release&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从图中，我们可以发现第一次代码部署之后导致了大量的警告信息，经过随后的两次 Hotfix 之后，警告信息基本消除。&lt;/p&gt;

&lt;h2 id=&#34;总结:b7837abce316965fc5b3c43248c541ea&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文非常简要地介绍了 Graphite 和 Grafana 的一些特性和使用场景。我也是在实习当中第一次接触到这两个工具，很多具体的细节还在摸索之中。&lt;/p&gt;

&lt;p&gt;总之，Graphite 是一个易扩展，使用简便的监控绘图工具，在这里推荐给大家使用。&lt;/p&gt;

&lt;h2 id=&#34;参考文献:b7837abce316965fc5b3c43248c541ea&#34;&gt;参考文献&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://obfuscurity.com/2014/01/Graphite-Tip-A-Better-Way-to-Store-Events&#34;&gt;Graphite Tip - A Better Way to Store Events&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codeascraft.com/2010/12/08/track-every-release/&#34;&gt;Tracking Every Release&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://joshhertz.se/post/making-annotations-in-graphana&#34;&gt;Making Annotations in Graphana&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>Sensu 简介</title>
            <link>http://yumminhuang.github.io/blog/2015/04/04/sensu-%E7%AE%80%E4%BB%8B/</link>
            <pubDate>Sat, 04 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/04/sensu-%E7%AE%80%E4%BB%8B/</guid>
            <description>

&lt;h2 id=&#34;sensu-简介:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu 简介&lt;/h2&gt;

&lt;p&gt;Sensu 是一款开源的监控框架。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sensuapp.org/docs/0.16/img/sensu-diagram-87a902f0.gif&#34; alt=&#34;Sensu components&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Sensu 采用 C/S 结构，有用来发送指令、存储数据的 Sensu Server 和被监控的对象 Sensu Client。Sensu Server 和 Sensu Client 之间使用 RabbitMQ 进行通信，Server 端使用 Redis 存储数据。每一个 Sensu Client 使用 JSON 进行设置。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;client&amp;quot;: {
    &amp;quot;name&amp;quot;: &amp;quot;i-424242&amp;quot;,
    &amp;quot;address&amp;quot;: &amp;quot;127.0.0.1&amp;quot;,
    &amp;quot;subscriptions&amp;quot;: [
      &amp;quot;production&amp;quot;,
      &amp;quot;webserver&amp;quot;
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，&lt;code&gt;subscriptions&lt;/code&gt; 指定了 Sensu Client 订阅哪些监控项目。 Sensu 采用了&lt;a href=&#34;http://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern&#34;&gt;订阅者模式&lt;/a&gt;，相应地，定义监控项目的时候则需要指定 &lt;code&gt;subscribers&lt;/code&gt;（后文中将会提及）。&lt;/p&gt;

&lt;h3 id=&#34;sensu-的优势:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu 的优势&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;纯 Ruby 实现，核心代码不超过 1000 行；&lt;/li&gt;
&lt;li&gt;配置简单，配置文件使用 JSON；&lt;/li&gt;
&lt;li&gt;结构简单，易扩展，很容易就能够上手编写插件；&lt;/li&gt;
&lt;li&gt;丰富的社区支持，&lt;a href=&#34;https://github.com/sensu/sensu-community-plugins&#34;&gt;Sensu Community Plugin&lt;/a&gt; 几乎包含了所有常用的监控项目。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;sensu-的结构:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu 的结构&lt;/h3&gt;

&lt;p&gt;简单来说，Sensu 分为 Check 和 Handler 两个部分。Sensu 经常被描述为「monitoring router」，因为它不仅可以用 Check 监控系统，还可以设置 Handler 根据当前的条件采取相应的行动。&lt;/p&gt;

&lt;h4 id=&#34;sensu-check:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu Check&lt;/h4&gt;

&lt;p&gt;Sensu Check 用来监控服务和资源。Check 由 Sensu Server 发出执行指令后在 Sensu Client 上运行。本质上，Sensu Check 是一个命令或者脚本，用来把数据输出到 &lt;code&gt;STDOUT&lt;/code&gt; 或者 &lt;code&gt;STDERR&lt;/code&gt;；同时，用返回值（exit status code）来指示状态：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;0&lt;/code&gt;： OK&lt;/li&gt;
&lt;li&gt;&lt;code&gt;1&lt;/code&gt;：WARNING&lt;/li&gt;
&lt;li&gt;&lt;code&gt;2&lt;/code&gt;：CRITICAL&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;gt;3&lt;/code&gt;：UNKNOWN or CUSTOM&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，只要定义好返回值和输出，很容易就可以写出一个 Sensu Check。下面就是一个用来监测 &lt;code&gt;chef-client&lt;/code&gt; 进程是否在运行的 Ruby 脚本。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;procs = `ps aux`
  running = false
  procs.each_line do |proc|
    running = true if proc.include?(&#39;chef-client&#39;)
  end
  if running
    puts &#39;OK - Chef client daemon is running&#39;
    exit 0
  else
    puts &#39;WARNING - Chef client daemon is NOT running&#39;
    exit 1
  end 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;写好一个Check的脚本，需要在配置文件中添加它。比如下面,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;checks&amp;quot;: {
    &amp;quot;chef_client&amp;quot;: {
      &amp;quot;command&amp;quot;: &amp;quot;check-chef-client.rb&amp;quot;,
      &amp;quot;subscribers&amp;quot;: [
        &amp;quot;production&amp;quot;
      ],
      &amp;quot;interval&amp;quot;: 60,
      &amp;quot;handlers&amp;quot;: [
        &amp;quot;pagerduty&amp;quot;,
        &amp;quot;mail&amp;quot;
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;subscribers&lt;/code&gt; 用来指定订阅者。&lt;code&gt;interval&lt;/code&gt; 定义检查的周期为 &lt;code&gt;60s&lt;/code&gt;，&lt;code&gt;handlers&lt;/code&gt; 则告诉 Sensu 当此 Check 出现异常时使用 &lt;code&gt;pagerduty&lt;/code&gt; 和 &lt;code&gt;mail&lt;/code&gt; 这两个 Handler。&lt;/p&gt;

&lt;h4 id=&#34;sensu-handler:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu Handler&lt;/h4&gt;

&lt;p&gt;Sensu Handler 用来处理 Sensu Check 产生的 Event，例如发送邮件通知，将采集的数据发送到 &lt;a href=&#34;http://graphite.wikidot.com&#34;&gt;Graphite&lt;/a&gt;，等等。 Handler 有不同的类型，有常用的 &lt;code&gt;Pipe&lt;/code&gt;，可以将 Event 传入到 &lt;code&gt;STDIN&lt;/code&gt;（可以理解为 &lt;code&gt;cat event.json | handler&lt;/code&gt;）；有 TCP/UDP，将 Event 传入到 Socket 发送。&lt;/p&gt;

&lt;p&gt;下面是一个简单的 Sensu Handler 定义，用来将 Event 的内容发送到指定的邮箱地址。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;handlers&amp;quot;: {
    &amp;quot;mail&amp;quot;: {
      &amp;quot;type&amp;quot;: &amp;quot;pipe&amp;quot;,
      &amp;quot;command&amp;quot;: &amp;quot;mailx -s &#39;sensu event&#39; email@address.com&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;基于-sensu-的安全更新监控工具:b6bdba0566435a1fdf738209881f4749&#34;&gt;基于 Sensu 的安全更新监控工具&lt;/h2&gt;

&lt;p&gt;接下来，结合我这次实习里的一个项目来详细地介绍一下 Sensu 的使用。&lt;/p&gt;

&lt;h3 id=&#34;需求:b6bdba0566435a1fdf738209881f4749&#34;&gt;需求&lt;/h3&gt;

&lt;p&gt;我们公司在 AWS 上有大约350个实例&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:b6bdba0566435a1fdf738209881f4749:Instance&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:b6bdba0566435a1fdf738209881f4749:Instance&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，运行的是 Ubuntu 操作系统。服务器上的软件会不定期收到更新，包括非常重要的安全更新。我们希望及时知道服务器上有哪些安全更新可以安装，最好可以通过邮件的方式通知。通知里应当至少包括如下信息：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;更新的软件包名称；&lt;/li&gt;
&lt;li&gt;软件包当前的版本；&lt;/li&gt;
&lt;li&gt;可供安装的版本。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;此外，一个邮件里包含 350 台机器的信息显然不方便阅读。恰好公司的 350 台服务器根据功能分为若干个 &lt;code&gt;subnet&lt;/code&gt;，如 dev，tst，stg 等。所以，最好可以为每一个 subnet 生成一份安全更新的报告。&lt;/p&gt;

&lt;h3 id=&#34;实现:b6bdba0566435a1fdf738209881f4749&#34;&gt;实现&lt;/h3&gt;

&lt;h4 id=&#34;安全更新的信息收集:b6bdba0566435a1fdf738209881f4749&#34;&gt;安全更新的信息收集&lt;/h4&gt;

&lt;p&gt;使用 Debian/Ubuntu 的用户都知道，每次登陆都会看到类似的信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;17 packages can be updated.
6 updates are security updates.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以此为源头，我找到了 Debian 系统内自带的一个 Python 脚本 &lt;code&gt;/usr/lib/update-notifier/apt_check.py&lt;/code&gt;。它可以调用 &lt;a href=&#34;https://apt.alioth.debian.org/python-apt-doc/index.html&#34;&gt;python-apt&lt;/a&gt; 库收集系统当前可以安装的安全更新。以此脚本为基础稍加改动就可以得到我们所需要的信息。&lt;/p&gt;

&lt;p&gt;我已经把修改过的脚本做成了一个 &lt;a href=&#34;https://github.com/sensu/sensu-community-plugins/blob/master/plugins/system/package-updates-metric.py&#34;&gt;Sensu Plugin&lt;/a&gt; 提交到了 Sensu 社区。&lt;/p&gt;

&lt;p&gt;####信息的汇集和通知
第一步非常顺利，但是还有问题需要解决：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Python 脚本只能收集本地的信息，如何把350台服务器的信息汇集在一起？&lt;/li&gt;
&lt;li&gt;信息汇集完了如何进行分类、通知？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;为了解决这两个问题，就需要用到本文的主角 Sensu  了。&lt;/p&gt;

&lt;p&gt;第一个问题是汇集多台机器的检查结果。事实上，通常的Sensu Check 也只能检查一台机器。为了解决第一个问题，我使用了 &lt;a href=&#34;http://sensuapp.org/docs/0.16/api_aggregates&#34;&gt;Sensu Aggregate API&lt;/a&gt;。我们可以把一个 Sensu Check 定义成 &lt;a href=&#34;http://sensuapp.org/docs/0.16/checks&#34;&gt;Aggregate Check&lt;/a&gt;，然后通过 API 可以得到所有该 Check 的结果。&lt;/p&gt;

&lt;p&gt;因此，整个安全更新监控工具使用了两个 Sensu Check。第一个 Aggregate Check 运行在所有的服务器上，用来收集本地的安全更新。第二个 Check 运行在一台服务器上，它会调用 Aggregate API 读取第一个 Check 的结果，再加以归类、分析。如果有安全更新可以安装，就触发 Handler 发送通知邮件。&lt;/p&gt;

&lt;p&gt;第一个 Check 的定义：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;checks&amp;quot;: {
    &amp;quot;apt-check&amp;quot;: {
      &amp;quot;command&amp;quot;: &amp;quot;package-updates-metric.py&amp;quot;,
      &amp;quot;subscribers&amp;quot;: [
        &amp;quot;production&amp;quot;
      ],
      &amp;quot;interval&amp;quot;: 28800,
      &amp;quot;aggregate&amp;quot;: true,
      &amp;quot;handler&amp;quot;: false
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第二个Check的定义：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;checks&amp;quot;: {
    &amp;quot;aggregate_apt_check&amp;quot;: {
      &amp;quot;command&amp;quot;: &amp;quot;package-updates-check.py&amp;quot;,
      &amp;quot;subscribers&amp;quot;: [
        &amp;quot;mg102.ops&amp;quot;
      ],
      &amp;quot;publish&amp;quot;: false,
      &amp;quot;handler&amp;quot;: &amp;quot;package-updates-notify.rb&amp;quot;,
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，&lt;code&gt;package-updates-check.py&lt;/code&gt; 是另外一个 Python 脚本，主要是访问 API 并且读取结果。如果发现了安全更新就输出结果并返回&lt;code&gt;1&lt;/code&gt;，这样就可以触发 &lt;code&gt;package-updates-notify.rb&lt;/code&gt;。这是一个 Ruby 脚本，用来读取第二个 Check 的结果，再把结果分成不同的 subnet 发送邮件。
另外，这里设置了 &lt;code&gt;&amp;quot;publish&amp;quot;: false&lt;/code&gt;，所以这个 Check 需要手工启动（因为没有必要定时调用，每天一次足矣），可以通过以下命令来手动请求 Sensu Check。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -XPOST http://api.sensu.example.com:4567/check/request -d &#39;{&amp;quot;check&amp;quot;:&amp;quot;aggregate_apt_check&amp;quot;}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我添加了一个 Cron job 每天早上定时调用该命令。这样每天早上一到办公室就可以及时获知所有服务器是否需要更新。&lt;/p&gt;

&lt;p&gt;整个工具就基本完成了。剩下的内容就是写一个 Chef 的 Recipe，把工具部署到所有的服务器上。&lt;/p&gt;

&lt;h3 id=&#34;总结:b6bdba0566435a1fdf738209881f4749&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;这就是我的第一个 Sensu 项目。学习一门编程语言或一个工具最好的方法就是用它来做一个项目。的确，通过这个项目让我对 Sensu 的功能和特性有了比较清楚的了解。&lt;/p&gt;

&lt;p&gt;整个安全更新监控工具的实现描述得很简单，但是从立项到投入实际应用还是用了我一个月的时间，后期还花费了一些时间在修复 Bug 上。因为很多工具都是初次使用，包括第一次接触 Sensu，第一次使用 Ruby 做项目，第一次使用 Chef，实现的过程中边学边做，还是走了不少弯路。&lt;/p&gt;

&lt;p&gt;本文里只列出大致的框架，有一些代码没有贴出，贴出的代码也非完全准确。但是思路和意思已经都展现清楚了。&lt;/p&gt;

&lt;p&gt;更加详细的内容可以参阅 &lt;a href=&#34;http://sensuapp.org/docs/0.16/overview&#34;&gt;Sensu 文档&lt;/a&gt;。&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:b6bdba0566435a1fdf738209881f4749:Instance&#34;&gt;「实例」（Instance）这个说法听上去非常别扭，若无特别说明下文中「服务器」即指 AWS 实例。
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:b6bdba0566435a1fdf738209881f4749:Instance&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>3 个月运维工作之总结</title>
            <link>http://yumminhuang.github.io/blog/2015/04/01/3-%E4%B8%AA%E6%9C%88%E8%BF%90%E7%BB%B4%E5%B7%A5%E4%BD%9C%E4%B9%8B%E6%80%BB%E7%BB%93/</link>
            <pubDate>Wed, 01 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/01/3-%E4%B8%AA%E6%9C%88%E8%BF%90%E7%BB%B4%E5%B7%A5%E4%BD%9C%E4%B9%8B%E6%80%BB%E7%BB%93/</guid>
            <description>&lt;p&gt;自从 1 月 5 日开始实习至今，在 Operation Team 已经工作了三个月。我觉得有必要对工作进行一下总结。既是我对三个月来所学新知识的归纳，也是对运维工作的一些思考。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;这次实习并非是我第一次接触运维工作。2014 年夏天，我有一份两个月的暑期实习。当时实习工作的职位是 *Backend Software Engineer*，但事实上所完成的绝大部分工作的内容是关于运维，主要有 &lt;a href=&#34;http://aws.amazon.com/autoscaling/&#34;&gt;AWS Auto Scaling&lt;/a&gt; 的搭建（关于这部分内容可以参见之前的一篇 &lt;a href=&#34;http://yumminhuang.github.io/zai-aws-auto-scaling-group-zhong-ti-huan-instance.html&#34;&gt;博文&lt;/a&gt;）和基于 &lt;a href=&#34;http://aws.amazon.com/cloudwatch/&#34;&gt;AWS Cloudwatch&lt;/a&gt; 实现一些监测工具。所以也算对运维工作有一些经验。之后在找实习的时候，我也是有意识地找运维相关的职位。&lt;/p&gt;

&lt;p&gt;这里也顺便说一下暑期实习的公司。那是一个只有 5、6 个程序员的初创公司。公司所有的服务都搭建在 Amazon Web Service。运维可以说略显「简陋」：服务器的操作全部由 Python 脚本实现；代码的部署也是用 Python 脚本从 svn 下载再进行安装；系统监控全部部署在 Cloudwatch。对于只有十多台服务器的公司来说，这样的运维方法似乎也足够了。&lt;/p&gt;

&lt;p&gt;所以在这次实习之前，我对运维工作的印象还是停留在启动、监控、维护服务器，写一些脚本来实现自动化，最多在服务器出问题的时候做一下 &lt;a href=&#34;http://en.wikipedia.org/wiki/Hotfix&#34;&gt;Hotfix&lt;/a&gt;。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;但是当服务器数量到达几百台的时候，显然之前实习中所用的方法是不够的。这次实习所在公司的规模要比之前大得多，在 AWS 上大约有 350 台实例。因此接触到了更加专业的运维工具、工作方法和流程，对运维工作也有了更加深刻的认识。&lt;/p&gt;

&lt;p&gt;先说工具的使用。和开发、测试不同的是，运维工作会接触到各种工具，最近几个月接触到的工具包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自动化部署工具 &lt;a href=&#34;https://www.chef.io/chef/&#34;&gt;Chef&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Continuous_integration&#34;&gt;持续集成（CI）&lt;/a&gt; 工具 &lt;a href=&#34;https://jenkins-ci.org/&#34;&gt;Jenkins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;监控框架 &lt;a href=&#34;http://sensuapp.org/&#34;&gt;Sensu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;数据绘图工具 &lt;a href=&#34;http://graphite.wikidot.com/&#34;&gt;Graphite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码质量管理系统 &lt;a href=&#34;http://www.sonarqube.org/&#34;&gt;SonarQube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最让我印象深刻的应该是 Jenkins，第一次见识到自动化 CI 的感觉大概就和当年用了一学期 Turbo C 后第一次见到 Eclipse 一样。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://media.tumblr.com/fe40a2da7c8e594479f48fd8450817d5/tumblr_inline_nczuo9C9ov1raprkq.gif&#34; alt=&#34;Demonstrating end-to-end automation to new employees&#34; /&gt;&lt;/p&gt;

&lt;p&gt;每一个工具都自成体系，组合在一起又成为了相当复杂的运维系统。争取未来一段时间内，写一些文章来总结这些工具。&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;Welcome to Operation team! Every Ops guy has crashed a server.&lt;/p&gt;

&lt;p&gt;&amp;ndash; 工作近一个月，我第一次弄崩服务器程序之后，同事如是说&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;一个体会是运维工作对知识面要求挺高的。要能够编程、测试，因为很多时候要自己实现工具，这个时候要自己编码，自己测试。而且知识点很繁杂，操作系统、网络、软件工程这些学科的知识都会经常使用。&lt;/p&gt;

&lt;p&gt;另一个体会是运维工作不只是管理服务器、部署程序，而是深入到公司开发流程的各个方面。开发人员写的代码需要有工具能够自动运行测试，自动合并到 Master 分支。测试人员做完测试要生成测试覆盖率的报告。还有常规的服务器管理，系统监测，所有这些林林总总的基础设施搭建都需要运维团队来做。就连办公室断了网也是由我们组来处理。&lt;/p&gt;

&lt;p&gt;更为重要的体会还是在于运维工作的方法学方面。总的来说，感觉运维工作在很大程度上要靠经验的积累。下面一些内容未必正确，但都是工作三个月来自己的切身感受。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对系统的熟悉重于对算法的掌握&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;并非算法不重要，而是运维工作更多的时间里是在和 API、工具打交道，需要自己设计算法的场合相对比较少。现在的 API、工具越来越强大，很多复杂的算法都已经被封装起来了，不需要程序员自己来实现。但是，运维工作对系统熟悉的要求比较高。具体来说，你需要清楚地知道当前系统里每个工具做什么，怎么做。对软件工程各个环节中可能用到的工具要有了解，至少知道它能干什么，不能干什么。而且你还要知道不同工具如何配合使用，因为很多任务需要系统内几个工具一起合作。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对一个任务具体过程的熟悉重于对编程细节实现&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一方面，运维工作自身的编程工作一般都比较简单。以部署来说，借助于像 Chef 这样的自动化部署工具，软件包的下载、配置文件的修改等琐碎细节都已经被隐藏，只需要编写脚本定义部署的步骤就可以了。所以在准备部署一个服务的时候，我们不需要知道怎样下载软件包，如何读、写文件，但是要非常清楚地知道搭建这个服务要经过哪几个步骤。有时候甚可能还需要清楚地知道每个步骤的顺序，比如服务的配置需要改变，是先停止程序，还是先修改配置文件。这就要求对每个任务的流程都很熟悉。&lt;/p&gt;

&lt;p&gt;另一方面，运维不像开发那样需要知道公司业务的细节。运维工作是独立于公司业务的，不需要相应的 Domain Knowledge。我至今也不太了解公司核心业务是如何实现的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;成本估算的能力&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;运维工作是以成本为中心的。在公司里不能带来实际的收入，我们需要做的是花尽可能少的钱来提高公司的效率，保证服务的稳定。所以在接手一个任务之前，要估算不同解决方案的成本。有时候遇到一个问题，市场上有现成的收费工具可以用。如果不想花钱，自己来实现需要花费多少时间。&lt;/p&gt;

&lt;p&gt;刚入职时的一个任务是：检查公司里几百台服务器是否有安全更新需要安装，要有通知功能，能够列出有哪些更新，并且支持一键安装。现成的解决方案有针对 Ubuntu 系统的 &lt;a href=&#34;https://landscape.canonical.com/&#34;&gt;Canonical Landscape&lt;/a&gt;。功能齐全，界面美观，但是其价格到了瞠目结舌的地步，每 100 台机器一年要 $75K，难以想象一个 Linux 管理工具卖这么贵会不会有人用。这个成本显然是不能接受的。后来又找到一个独立开发者开发的补丁管理工具 &lt;a href=&#34;https://sysward.com/&#34;&gt;Sysward&lt;/a&gt;，完全符合我们最初的需求，但是估算了一下，用这个每个月的费用仍然有 $700。最后考虑到这个需求并不是非常着急，而且在公司所使用的开源工具的基础上可以做出来，所以决定自己来做这个工具。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上就是实习三个月以来，身为一个运维新人的体会和思考，想法或许还有些不成熟、不准确。实习还有四个月时间结束，希望届时能够有更多的体会可以总结。&lt;/p&gt;
</description>
          </item>
        
      
    
  </channel>
</rss>
