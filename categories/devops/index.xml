<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Devops on 临水轩志</title>
    <link>http://yumminhuang.github.io/categories/devops/</link>
    <description>Recent content in Devops on 临水轩志</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 13 Feb 2016 16:36:21 -0500</lastBuildDate>
    <atom:link href="http://yumminhuang.github.io/categories/devops/index.xml" rel="self" type="application/rss+xml" />
    
      
        
          <item>
            <title>Git 工作流</title>
            <link>http://yumminhuang.github.io/blog/2016/02/13/git-%E5%B7%A5%E4%BD%9C%E6%B5%81/</link>
            <pubDate>Sat, 13 Feb 2016 16:36:21 -0500</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2016/02/13/git-%E5%B7%A5%E4%BD%9C%E6%B5%81/</guid>
            <description>

&lt;p&gt;Git 可能是每个开发者最常用的工具之一。Git 让开发团队更加方便地进行版本控制和多人协作。但是如果开发团队没有约定如何使用 Git 工作，很可能会导致工作变得一团糟。其中最大的问题是同时存在太多的开发中的分支，每个分支都包含了部分修改。最终开放团队很难弄清楚哪一个分支应该继续开发，或者把它发布成产品。&lt;/p&gt;

&lt;p&gt;正如编程过程中变量命名需要一套标准的命名规则（&lt;a href=&#34;https://en.wikipedia.org/wiki/Naming_convention_(programming&#34;&gt;Naming convention&lt;/a&gt;)）一样，开发团队在使用 Git 的时候，也需要一套标准的工作流，从而确保高效的开发、测试和部署。&lt;/p&gt;

&lt;p&gt;关于 Git 的工作流，业界已经有了很多讨论。&lt;/p&gt;

&lt;h3 id=&#34;git-flow:6a03d3862c7b57291f07850ad6a5776a&#34;&gt;Git flow&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://nvie.com/posts/a-successful-git-branching-model/&#34;&gt;git-flow&lt;/a&gt; 最早在2010年提出。用下面这幅图可以概括 git-flow 的主要内容。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nvie.com/img/git-model@2x.png&#34; alt=&#34;git-flow&#34; style=&#34;width: 500px;&#34;/&gt;&lt;/p&gt;

&lt;p&gt;git-flow 包含一个 &lt;em&gt;master&lt;/em&gt; 分支、一个 &lt;em&gt;develop&lt;/em&gt; 分支，&lt;em&gt;release&lt;/em&gt; 分支、&lt;em&gt;hotfix&lt;/em&gt; 分支和若干 &lt;em&gt;feature&lt;/em&gt; 分支。开发工作在 &lt;code&gt;develop&lt;/code&gt; 进行，然后提交到 &lt;code&gt;release&lt;/code&gt; ，最后合并到 &lt;code&gt;master&lt;/code&gt;。但是 git-flow 太复杂了，需要维护很多分支，开发时还要不停切换分支。所以，到了后来有一些&lt;a href=&#34;http://insights.thoughtworkers.org/gitflow-consider-harmful/&#34;&gt;文章&lt;/a&gt;就对 git-flow 提出了质疑。&lt;/p&gt;

&lt;h3 id=&#34;github-flow:6a03d3862c7b57291f07850ad6a5776a&#34;&gt;Github flow&lt;/h3&gt;

&lt;p&gt;Github 针对 git-flow 的不足，并且充分利用 Pull Request 功能，提出了一套更为简单的工作流 —— &lt;a href=&#34;http://scottchacon.com/2011/08/31/github-flow.html&#34;&gt;Github flow&lt;/a&gt;。 Github flow 简化了分支：只有一个可部署的 &lt;code&gt;master&lt;/code&gt; 分支；新添加的代码（不区分 feature、bug-fix）都放在基于 master 创建的新分支里；分支的名称应当能描述出问题（Issue），例如 &lt;code&gt;new-oauth2-scopes&lt;/code&gt;。Github flow 同时还强调持续交付（&lt;a href=&#34;http://martinfowler.com/bliki/ContinuousDelivery.html&#34;&gt;Continuous delivery&lt;/a&gt;）和使用当时 Github 新推出的 Pull Request 进行代码审查（&lt;a href=&#34;https://en.wikipedia.org/wiki/Code_review&#34;&gt;Code review&lt;/a&gt;）。经过几年的发展，Github flow 基本上已经成为业内的标准：几乎所有的代码托管网站、使用 Git 的 SaaS、Git 软件都有基于 branch 的 Pull Request 功能。&lt;/p&gt;

&lt;h3 id=&#34;gitlab-flow:6a03d3862c7b57291f07850ad6a5776a&#34;&gt;Gitlab flow&lt;/h3&gt;

&lt;p&gt;但是 Github flow 仍有不足和值得改进的地方，所以 Gitlab 提出了 &lt;a href=&#34;https://about.gitlab.com/2014/09/29/gitlab-flow/&#34;&gt;Gitlab flow&lt;/a&gt;。Github flow 强调持续交付，合并到 &lt;code&gt;master&lt;/code&gt; 的代码要立刻部署到线上。Gitlab 指出这种模式并非适用于所有的开放环境。比如有的软件可能隔几个月，甚至几年才会发布新版本。因此（如下图所示），在这些例子里，创建一个 &lt;em&gt;production&lt;/em&gt; 或 &lt;em&gt;release&lt;/em&gt; 分支来管理发布的代码是有必要的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://about.gitlab.com/images/git_flow/production_branch.png&#34; alt=&#34;gitlab-flow&#34; /&gt;&lt;/p&gt;

&lt;p&gt;另外，Gitlab flow 还强调代码的任何修改都应该开始于一个目标明确的Issue。因此，为一个 Issue 创建新分支时，这个分支的名字应该以 Issue 的编号开始，比如 &lt;code&gt;15-require-a-password-to-change-it&lt;/code&gt;。Commit 的信息或 Merge Request 的描述里应关联相关的 Issue，如&lt;code&gt;fixes #14&lt;/code&gt; 或 &lt;code&gt;closes #67&lt;/code&gt;，这样合并到 &lt;code&gt;master&lt;/code&gt; 的时候可以自动关闭相应的 Issue。&lt;/p&gt;

&lt;h3 id=&#34;git-工作流的需求:6a03d3862c7b57291f07850ad6a5776a&#34;&gt;Git 工作流的需求&lt;/h3&gt;

&lt;p&gt;在实际开发的过程中，有各种各样的需要。鉴于诸如 &lt;a href=&#34;https://en.wikipedia.org/wiki/Scrum_(software_development&#34;&gt;Scrum&lt;/a&gt;) 之类的敏捷开发方法已经被业界采用，再结合我以前的经验，我觉得 Git 工作流应当结合以下功能：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;缺陷追踪（&lt;a href=&#34;https://en.wikipedia.org/wiki/Issue_tracking_system&#34;&gt;Issue tracking&lt;/a&gt;）；&lt;/li&gt;
&lt;li&gt;代码审查；&lt;/li&gt;
&lt;li&gt;持续集成（&lt;a href=&#34;http://martinfowler.com/articles/continuousIntegration.html&#34;&gt;Continuous integration&lt;/a&gt;）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;首先，缺陷追踪是非常有必要的。Issue 列表不仅可以帮助整个团队及时了解当前存在的问题和未来需要增加的功能，也可以用来帮助在每个 sprint 前制定 &lt;a href=&#34;https://en.wikipedia.org/wiki/Scrum_(software_development&#34;&gt;product backlog&lt;/a&gt;#Product_backlog)。而且现在市面上大部分的缺陷追踪系统，比如 &lt;a href=&#34;https://www.atlassian.com/software/jira&#34;&gt;JIRA&lt;/a&gt;、&lt;a href=&#34;https://guides.github.com/features/issues/&#34;&gt;Github Issue&lt;/a&gt;， 都整合了 Git，可以通过 Issue 编号相互链接。&lt;/p&gt;

&lt;p&gt;代码审查的重要性不必赘述，在开发过程中，团队成员之间互相检查对于保证代码质量是非常关键的。&lt;/p&gt;

&lt;p&gt;持续集成同样有助于提高代码质量。快速持续的合并到 &lt;code&gt;master&lt;/code&gt; 可以确保团队在最新、最准确的代码上工作，避免了不必要的冲突。通过使用诸如 &lt;a href=&#34;http://yumminhuang.github.io/blog/2015/06/02/jenkins-%E7%AE%80%E4%BB%8B/&#34;&gt;Jenkins&lt;/a&gt;、&lt;a href=&#34;http://yumminhuang.github.io/blog/2015/06/20/travis-ci/&#34;&gt;Travis CI&lt;/a&gt; 之类的持续集成工具，可以自动测试每一个 Pull Request，从而保证 &lt;code&gt;master&lt;/code&gt; 当中代码的正确性。&lt;/p&gt;

&lt;p&gt;另外，Git 工作流还需要满足的要求：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;代码隔离；&lt;/li&gt;
&lt;li&gt;便于版本回溯；&lt;/li&gt;
&lt;li&gt;可以在尽可能多的平台上使用。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;使用 Git 分支最主要的目的就是实现代码隔离，即：每个人能够各自独立工作，互不干扰；未完成和出错的代码不会混在准备发布的代码里。&lt;/p&gt;

&lt;p&gt;使用 Git 还应该能够快速地版本回溯。一旦当前发布的代码出现问题，要能够立刻回溯到上一个可发布版本。&lt;/p&gt;

&lt;p&gt;最后，应该能在尽可能多的平台上，无论是 Github、BitBucket 这样的 SaaS，还是自己使用 Gitlab 搭建的服务器，实践这个工作流。最好可以让 GUI 和 CLI 都能够完成整个工作流。&lt;/p&gt;

&lt;h3 id=&#34;改进的-git-工作流:6a03d3862c7b57291f07850ad6a5776a&#34;&gt;改进的 Git 工作流&lt;/h3&gt;

&lt;p&gt;基于 Github flow，并加入 Gitlab flow 的一些优点，我设计了一个改进的 Git 工作流：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;master&lt;/code&gt; 时刻保持「可交付」的状态；&lt;/li&gt;
&lt;li&gt;根据 Issue 列表，基于 &lt;code&gt;master&lt;/code&gt; 创建新分支，并采用描述性的命名方法；&lt;/li&gt;
&lt;li&gt;定期 push commits 到服务器；&lt;/li&gt;
&lt;li&gt;在需要反馈、帮助，或解决了一个 issue 时，创建 Pull Request，同时添加 Reviewer；&lt;/li&gt;
&lt;li&gt;使用持续集成技术运行自动化测试，保证测试通过，并进行代码审查；&lt;/li&gt;
&lt;li&gt;合并 Pull Request 到 &lt;code&gt;master&lt;/code&gt; 分支；&lt;/li&gt;
&lt;li&gt;为发布的版本添加 tag。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;master&lt;/code&gt; 时刻保持「可交付」的状态&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这条应该作为工作流中最基本的准则严格执行。作为 Git 里默认的分支，我们应当保证 &lt;code&gt;master&lt;/code&gt; 里的代码随时可以发布。这样，一旦代码出现了问题，我们可以回到 &lt;code&gt;master&lt;/code&gt; 中之前的版本。&lt;/p&gt;

&lt;p&gt;软件测试的一个基本原则就是无法保证代码中没有 bug。所以，我们只能确保代码满足需求说明文档，是可以发布、部署的状态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;根据 Issue 列表，基于 &lt;code&gt;master&lt;/code&gt; 创建新分支，并采用描述性的命名方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如前一条准则所述，&lt;code&gt;master&lt;/code&gt; 里的代码可以认为是正确的，我们可以基于 &lt;code&gt;master&lt;/code&gt; 放心地创建新分支。&lt;/p&gt;

&lt;p&gt;虽然没有必要单独创建 &lt;code&gt;hotfix&lt;/code&gt; 之类的分支，我认为还是有必要在命名时，通过添加前缀 &lt;code&gt;feature/&lt;/code&gt;、&lt;code&gt;fix/&lt;/code&gt;、&lt;code&gt;hotfix/&lt;/code&gt;，对每条分支的内容加以区分。比如，增加一个新特性时，可以给分支命名为 &lt;code&gt;feature/oauth2-login&lt;/code&gt;，修复一个 bug 时，可以给分支命名为&lt;code&gt;fix/memory-leak&lt;/code&gt;。这样既简化了分支管理，避免一个分支存在太长时间，也方便快速了解一个分支的作用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;定期 push commits 到服务器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;定期 push commits 一来可以把代码备份到服务器，也可以让整个团队了解项目的进展。Push 的频率取决于具体的情况。开发一个新功能可能需要花费很长的时间，可以相应地降低 push 的频率；而修复一个 bug，则可能较为紧急，应尽可能快地 push 到服务器上。&lt;/p&gt;

&lt;p&gt;另外，明确的 Commit message 有助于团队协作、回忆开发过程。关于如何写 Commit message，可以参考这篇 &lt;a href=&#34;http://www.ruanyifeng.com/blog/2016/01/commit_message_change_log.html&#34;&gt;Commit message 和 Change log 编写指南&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在需要反馈、帮助，或解决了一个 issue 时，创建 Pull Request，同时添加 Reviewer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现在几乎所有的代码托管平台都支持 Pull Request 功能，使用 Pull Request 可以方便地进行团队内的代码审查。有的工具，比如 Bitbucket，可以直接添加 Reviewer。其它工具，比如 Github，也可以通过 &lt;a href=&#34;https://github.com/blog/1121-introducing-team-mentions&#34;&gt;@ 功能&lt;/a&gt;来提醒团队成员进行审查。&lt;/p&gt;

&lt;p&gt;并非在完成全部更改时才可以创建 Pull Request，在遇到问题需要团队帮助或反馈时，同样可以创建 Pull Request，并在 Pull Request 的描述里简述当前的进度。通过和 Reviewer 讨论可以更快地解决问题。这样做也方便让团队其他成员了解项目的进展。&lt;/p&gt;

&lt;p&gt;在 Pull Request 的描述里，可以链接对应的 Issue，方便索引。Github 等也可以在分支被合并的时候&lt;a href=&#34;https://github.com/blog/1506-closing-issues-via-pull-requests&#34;&gt;自动关闭对应的 Issue&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;使用持续集成技术运行自动化测试，保证测试通过，并进行代码审查&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;自动化测试在此不再赘述。我们应当保证所有测试用例都被通过，并且得到所有 Reviewer 的许可。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;合并 Pull Request 到 &lt;code&gt;master&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在测试通过，并且所有 Reviewer 都同意之后，就可以把分支里的代码合并到 &lt;code&gt;matser&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;大部分工具都可以在 Pull Request 的图形化页面里直接合并。如果使用命令行，应当使用 &lt;code&gt;git merge --no-ff feature/xxx&lt;/code&gt; 来进行合并。如下图所示，使用 &lt;code&gt;--no-ff&lt;/code&gt; 参数后，会执行正常合并，并在 &lt;code&gt;master&lt;/code&gt; 上生成一个新节点，而非「快进式合并（fast-forward merge）」。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://image.beekka.com/blog/201207/bg2012070506.png&#34; alt=&#34;--no-ff merge&#34; style=&#34;height: 300px;&#34;/&gt;&lt;/p&gt;

&lt;p&gt;这样做可以保证版本演进的清晰。&lt;/p&gt;

&lt;p&gt;合并到 &lt;code&gt;master&lt;/code&gt; 之后，创建的分支应当删除。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为发布的版本添加 tag&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;需要发布或者部署时，从 &lt;code&gt;master&lt;/code&gt; 里选择最新的版本。可以给该版本添加 tag，比如 &lt;code&gt;v1.0beta&lt;/code&gt;、&lt;code&gt;2.3.2&lt;/code&gt; 等。&lt;/p&gt;

&lt;p&gt;有时候针对不同的演示环境（Staging），可能有必要维护单独的 &lt;em&gt;production&lt;/em&gt; 分支，可以从 &lt;code&gt;master&lt;/code&gt; &lt;a href=&#34;https://git-scm.com/docs/git-cherry-pick&#34;&gt;cherry-pick&lt;/a&gt; 指定的版本到 &lt;code&gt;production&lt;/code&gt;。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;这是一个基于 Github flow 和 Gitlab flow 的，又根据我自己的经验改进的 Git 工作流，可能还有一些值得改进的地方。也许未来随着开发经验的增加，我会尝试完善这整个流程。&lt;/p&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>Travis CI</title>
            <link>http://yumminhuang.github.io/blog/2015/06/20/travis-ci/</link>
            <pubDate>Sat, 20 Jun 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/06/20/travis-ci/</guid>
            <description>

&lt;p&gt;本文将主要介绍如何使用 &lt;a href=&#34;https://travis-ci.org&#34;&gt;Travis CI&lt;/a&gt; 托管 Github 上的开源项目，从而实现自动化测试、部署。同时，还将介绍使用 &lt;a href=&#34;https://coveralls.io/&#34;&gt;Coveralls&lt;/a&gt; 来监测测试覆盖率。&lt;/p&gt;

&lt;h2 id=&#34;travis-ci:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;Travis CI&lt;/h2&gt;

&lt;p&gt;Travis CI 是一款 Web 端的 &lt;ruby&gt; 持续 &lt;rt&gt;Continuous&lt;/rt&gt;&lt;/ruby&gt; &lt;ruby&gt; 集成 &lt;rt&gt;Integration&lt;/rt&gt;&lt;/ruby&gt; 工具。&lt;/p&gt;

&lt;p&gt;Travis CI 采用 &lt;a href=&#34;https://en.wikipedia.org/wiki/Freemium&#34;&gt;「Freemium」&lt;/a&gt; 的模式：对 Github 上的开源项目免费，付费的话则可以托管私有项目。Github 上很多知名的开源项目都适用 Travis CI 来进行自动化测试。&lt;/p&gt;

&lt;p&gt;和 Jenkins 相比，Travis CI 要轻量很多。但是已经足以完成简单的自动化测试、部署。&lt;/p&gt;

&lt;h2 id=&#34;coveralls:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;Coveralls&lt;/h2&gt;

&lt;p&gt;Coveralls 用来显示代码覆盖率，从而可以让程序员及时了解代码质量。&lt;/p&gt;

&lt;p&gt;Coveralls 和 Travis CI 一样，仅对 Github 上的开源项目免费。Coveralls 支持包括 Travis CI、Jenkins 在内的绝大多数持续集成工具。&lt;/p&gt;

&lt;h2 id=&#34;样例:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;样例&lt;/h2&gt;

&lt;p&gt;接下来以 Python 项目为例，说明如何使用 Travis CI 和 Coveralls&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:583dfe1ccd5a6962c32f3c2bbdee5427:src&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:583dfe1ccd5a6962c32f3c2bbdee5427:src&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h3 id=&#34;依赖管理和虚拟环境:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;依赖管理和虚拟环境&lt;/h3&gt;

&lt;p&gt;我喜欢为每个项目新建一个 &lt;ruby&gt;virtualenv&lt;rt&gt; 虚拟环境 &lt;/rt&gt;&lt;/ruby&gt;，这样可以确保每个项目的开发环境相互独立，避免发生冲突。&lt;a href=&#34;https://virtualenvwrapper.readthedocs.org/en/latest/&#34;&gt;virtualenvwrapper&lt;/a&gt; 是一个让人方便使用 virtualenv 的小工具。它把如新建 virtualenv、切换 virtualenv 等常用的操作都封装成了简单的指令。&lt;/p&gt;

&lt;p&gt;我一般会在项目中添加一个 &lt;code&gt;requirements.txt&lt;/code&gt;，里面列出项目所依赖的 Pip 库。这样在 virtualenv 中，直接运行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以安装所有的库。&lt;/p&gt;

&lt;h3 id=&#34;单元测试和测试覆盖:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;单元测试和测试覆盖&lt;/h3&gt;

&lt;p&gt;对于 Python 项目，我喜欢使用 &lt;a href=&#34;https://nose.readthedocs.org/en/latest/&#34;&gt;nose&lt;/a&gt; 来进行单元测试。此外，我还会使用 &lt;a href=&#34;http://nedbatchelder.com/code/coverage/&#34;&gt;coverage.py&lt;/a&gt; 来测量代码的测试覆盖率。&lt;/p&gt;

&lt;p&gt;nose 对 coverage.py 的支持非常好，可以在 &lt;code&gt;nosetests&lt;/code&gt; 命令后添加一系列选项来生成覆盖率。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nosetests --with-coverage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以直接得到测试覆盖率的数据。&lt;/p&gt;

&lt;p&gt;详细的使用方法可以参见 &lt;a href=&#34;https://nose.readthedocs.org/en/latest/&#34;&gt;nose 的官方文档&lt;/a&gt; 和&lt;a href=&#34;http://nedbatchelder.com/code/coverage/cmd.html&#34;&gt;coverage.py 的官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;持续集成:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;持续集成&lt;/h3&gt;

&lt;p&gt;在 Github 上新建项目之后，在 Travis CI 的页面上开启该项目。（新建的项目可能不会及时出现在 Travis CI 页面上，需要手动同步一下 Github 的项目。）接着，在 Github 项目里添加 Travis CI 的配置文件 &lt;code&gt;.travis.yml&lt;/code&gt;。Travis CI 的配置使用的是非常易读的 YAML 文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;language: python
python:
    - 2.6
    - 2.7
# command to install dependencies
install:
    - pip install -r requirements.txt
    - pip install coveralls
# command to run tests
script:
    nosetests --cover-package=project --with-coverage
# coveralls
after_success:
    coveralls

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样地，也需要在 Coveralls 上开启相应的项目。&lt;/p&gt;

&lt;p&gt;这样，Github 的代码库在每次收到 &lt;code&gt;Push&lt;/code&gt; 和 &lt;code&gt;Pull Request&lt;/code&gt; 的时候，Travis CI 都会按照配置文件上的步骤自动运行测试（或者部署，本样例只有测试。），并且把测试覆盖率的数据发布到 Coveralls。&lt;/p&gt;

&lt;p&gt;详细的配置说明可以参见 &lt;a href=&#34;http://docs.travis-ci.com/&#34;&gt;Travis CI 的官方文档&lt;/a&gt; 和&lt;a href=&#34;https://coveralls.zendesk.com/hc/en-us&#34;&gt;Coveralls 的官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;其它:583dfe1ccd5a6962c32f3c2bbdee5427&#34;&gt;其它&lt;/h3&gt;

&lt;p&gt;Travis CI 和 Coveralls 都可以生成 &lt;ruby&gt; 图章 &lt;rt&gt;Badge&lt;/rt&gt;&lt;/ruby&gt;，用来显示 &lt;ruby&gt; 构建 &lt;rt&gt;Build&lt;/rt&gt;&lt;/ruby&gt; 的结果，或者测试覆盖率。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/yumminhuang/turbo-octo-meme&#34;&gt;&lt;img src=&#34;https://travis-ci.org/yumminhuang/turbo-octo-meme.svg?branch=master&#34; alt=&#34;Build Status&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以将这些图章（如果已经发布到 PyPi，还可以加上版本号、下载量的图章。）放在项目的 &lt;em&gt;README&lt;/em&gt; 文件里。&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:583dfe1ccd5a6962c32f3c2bbdee5427:src&#34;&gt;详细代码可参见 &lt;a href=&#34;https://github.com/yumminhuang/turbo-octo-meme&#34;&gt;turbo-octo-meme&lt;/a&gt;。
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:583dfe1ccd5a6962c32f3c2bbdee5427:src&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>Jenkins 简介</title>
            <link>http://yumminhuang.github.io/blog/2015/06/02/jenkins-%E7%AE%80%E4%BB%8B/</link>
            <pubDate>Tue, 02 Jun 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/06/02/jenkins-%E7%AE%80%E4%BB%8B/</guid>
            <description>

&lt;p&gt;在&lt;a href=&#34;http://yumminhuang.github.io/ji-yu-jenkinsde-pythondai-ma-ji-cheng-zheng-he.html&#34;&gt;之前的一篇文章中&lt;/a&gt;，曾经提及过 Jenkins。在本次实习中，Jenkins 是我每天都要使用的工具。在频繁的使用过程当中：通过实际工作感受了「持续集成」的概念（关于持续集成的概念，此处按下不表，待有时间的时候再详细总结。）；逐渐熟悉了 Jenkins 的使用，并且体会到其带来的方便。因此，希望总结一下 Jenkins 的使用。&lt;/p&gt;

&lt;p&gt;然而 Jenkins 不通过具体的案例难以体会其方便之处，网上相关使用说明之类的文章又颇多，所以本文仅谈个人使用中的体会，并非学习Jenkins使用的教程。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;jenkins是什么:e83bca251359d2ad1ae1277c1018011a&#34;&gt;Jenkins是什么&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://jenkins-ci.org/&#34;&gt;Jenkins&lt;/a&gt; 是一个用 Java 编写的开源的&lt;ruby&gt;持续&lt;rt&gt;Continuous&lt;/rt&gt;&lt;/ruby&gt; &lt;ruby&gt;集成&lt;rt&gt;Integration&lt;/rt&gt;&lt;/ruby&gt;工具。&lt;/p&gt;

&lt;p&gt;Jenkins 是用 Java 开发的（界面和 Eclipse一样，带着一股浓浓的 SWT 的味道，好在界面并不太影响使用。），对 Java 程序开发有天然的良好支持，如 JUnit/TestNG 测试，Maven、Ant 等 Java 开发中常用的工具都包含在 Jenkins 里。当然，Jenkins 也可以通过插件来实现其它语言的开发。&lt;/p&gt;

&lt;h3 id=&#34;jenkins的特性:e83bca251359d2ad1ae1277c1018011a&#34;&gt;Jenkins的特性&lt;/h3&gt;

&lt;p&gt;在使用的过程中，我体会比较深刻的特性有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;项目易于配置&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在 Jenkins 当中，我们可以新建 Job。在 Job 里，可以设置添加&lt;ruby&gt;构建脚本&lt;rt&gt;Build Script&lt;/rt&gt;&lt;/ruby&gt;。构建脚本支持 Bash、Ant、Makefile；Job 的参数、&lt;ruby&gt;元&lt;rt&gt;Meta&lt;/rt&gt;&lt;/ruby&gt;数据可以作为环境变量在脚本里直接使用，因此设置起来非常方便。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;种类繁多的插件&lt;/strong&gt;（这点也和 Eclipse 也颇为相似）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Jenkins 的开发者社区非常活跃，&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Plugins&#34;&gt;第三方插件&lt;/a&gt;很多，从而可以帮助我们实现很多常用的功能。
比如，Hipchat 插件可以在 Job 运行结束后把结果发送到 Hipchat 的聊天室里；Cobertura 插件可以显示测试覆盖率的数据。&lt;/p&gt;

&lt;h3 id=&#34;jenkins的使用场景:e83bca251359d2ad1ae1277c1018011a&#34;&gt;Jenkins的使用场景&lt;/h3&gt;

&lt;p&gt;在我们公司，Jenkins 主要被用来用于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;ruby&gt;构建&lt;rt&gt;Build&lt;/rt&gt;&lt;/ruby&gt;、&lt;ruby&gt;测试&lt;rt&gt;Test&lt;/rt&gt;&lt;/ruby&gt;、&lt;ruby&gt;部署&lt;rt&gt;Deploy&lt;/rt&gt;&lt;/ruby&gt;代码&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们可以通过一个 Job 实现以下流程：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;使用 Git 插件，从代码库下载任一版本或分支的源代码；&lt;/li&gt;
&lt;li&gt;编译代码；&lt;/li&gt;
&lt;li&gt;运行测试。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;或者是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;启动若干个 EC2 实例；&lt;/li&gt;
&lt;li&gt;将任一版本的代码部署到新建的实例上。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;所有的这些流程在 Jenkins 里，都只需要设置几个简单的参数（如分支的名称，或者是实例的个数），再点击运行按钮就可以了。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;自动化一些复杂的流程，如数据库的迁移、备份，系统更新的安装等等&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有一些常用，但是流程很复杂的过程，可以在 Jenkins 里通过 Job 来完成。&lt;/p&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>基于 Jenkins 的 Python 代码集成整合</title>
            <link>http://yumminhuang.github.io/blog/2015/04/17/%E5%9F%BA%E4%BA%8E-jenkins-%E7%9A%84-python-%E4%BB%A3%E7%A0%81%E9%9B%86%E6%88%90%E6%95%B4%E5%90%88/</link>
            <pubDate>Fri, 17 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/17/%E5%9F%BA%E4%BA%8E-jenkins-%E7%9A%84-python-%E4%BB%A3%E7%A0%81%E9%9B%86%E6%88%90%E6%95%B4%E5%90%88/</guid>
            <description>

&lt;p&gt;实习中最近做了一个多月的项目是将代码测试覆盖率整合到公司持续整合（Continuous Integration）的流程当中。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This project uses Java and XML. How it could be good?&lt;/p&gt;

&lt;p&gt;——组里的同事如此评价本项目&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;本文介绍该项目的大致流程，共分为两部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;介绍 *Automated python unit testing, code coverage and code quality analysis with Jenkins*（&lt;a href=&#34;http://bhfsteve.blogspot.com/2012/04/automated-python-unit-testing-code.html&#34;&gt;part1&lt;/a&gt;, &lt;a href=&#34;http://bhfsteve.blogspot.com/2012/04/automated-python-unit-testing-code_20.html&#34;&gt;part2&lt;/a&gt;, &lt;a href=&#34;http://bhfsteve.blogspot.com/2012/04/automated-python-unit-testing-code_27.html&#34;&gt;part3&lt;/a&gt;）中使用 Jenkins 实现自动化测试、得到代码覆盖率和代码质量的方法。&lt;/li&gt;
&lt;li&gt;简要介绍我们如何在这篇文章的基础上把代码覆盖率整合到公司的 Bitbucket 代码库当中。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;基于-jenkins-的-python-自动化测试工具:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;基于 Jenkins 的 Python 自动化测试工具&lt;/h3&gt;

&lt;p&gt;使用到的 Python 模块：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nedbatchelder.com/code/coverage/&#34;&gt;coverage&lt;/a&gt;：用来生成代码覆盖率的数据；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nose.readthedocs.org/en/latest/&#34;&gt;nose&lt;/a&gt;: 用来运行单元测试；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pylint.org&#34;&gt;pylint&lt;/a&gt;：用来得到 Python 代码质量的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用到的 Jenkins 插件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Cobertura+Plugin&#34;&gt;Cobertura plugin&lt;/a&gt;：用来显示代码覆盖率；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Git+Plugin&#34;&gt;GIT plugin&lt;/a&gt;：用来获取最新的代码；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.jenkins-ci.org/display/JENKINS/Violations&#34;&gt;Violations plugin&lt;/a&gt;：用来显示 pylint 的结果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;安装需要的 Jenkins 插件之后，在 Jenkins 当中新建一个作业（Job）接下来进行设置。&lt;/p&gt;

&lt;h4 id=&#34;从哪里得到代码:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;从哪里得到代码&lt;/h4&gt;

&lt;p&gt;如下图所以，在 Jenkins 的 &lt;strong&gt;Source Code Management&lt;/strong&gt; 当中可以添加 Git Repository。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://2.bp.blogspot.com/-hDwb_sbJZHk/T5lzDbCT76I/AAAAAAAAADg/adELp3TAeV8/s1600/Source+code.png&#34; alt=&#34;SCM&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Jenkins 同样支持 subversion 等 CVS 工具。&lt;/p&gt;

&lt;h4 id=&#34;什么时候运行作业:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;什么时候运行作业&lt;/h4&gt;

&lt;p&gt;在 Jenkins 中可以将 &lt;strong&gt;Build Triggers&lt;/strong&gt; 设置为 &lt;strong&gt;Poll SCM&lt;/strong&gt; 对代码库进行轮询。如下图，&lt;strong&gt;Schedule&lt;/strong&gt; 设为 &lt;code&gt;* * * * *&lt;/code&gt;（含义和 Cron 一样）表示每分钟检查一次代码库，看是否有更新。如果代码库有更新的话则运行 &lt;strong&gt;Build&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://3.bp.blogspot.com/-DewpmzsyWZo/T5lzXqPVOlI/AAAAAAAAADo/OA2Fxd1YTzY/s1600/Build+triggers.png&#34; alt=&#34;Poll SCM&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当然，也可以使用 &lt;a href=&#34;http://git-scm.com/book/zh/v2/Customizing-Git-Git-Hooks&#34;&gt;Git Hook&lt;/a&gt;，从而避免轮询消耗过多的资源。&lt;/p&gt;

&lt;h4 id=&#34;运行什么:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;运行什么&lt;/h4&gt;

&lt;p&gt;添加一段 &lt;strong&gt;Build Script&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PYTHONPATH=&#39;&#39;
nosetests --with-xunit --all-modules --traverse-namespace --with-coverage --cover-package=project1 --cover-inclusive
python -m coverage xml --include=project1*
pylint -f parseable -d I0011,R0801 project1 | tee pylint.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这段 Shell 脚本中的三个命令：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;nosetests&lt;/code&gt; 命令运行单元测试；&lt;/li&gt;
&lt;li&gt;运行 &lt;code&gt;coverage&lt;/code&gt;，将覆盖率数据输出为 xml 文件；&lt;/li&gt;
&lt;li&gt;运行 &lt;code&gt;pylint&lt;/code&gt; 得到代码的质量数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;具体参数的含义可以参阅原文的第一、第二部分。&lt;/p&gt;

&lt;h4 id=&#34;显示结果:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;显示结果&lt;/h4&gt;

&lt;p&gt;上一步的 Build Script 有三个输出文件：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;nosetests.xml&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;coverage.xml&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pylint.out&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接着，在 Jenkins 当中，在 &lt;strong&gt;Publish JUnit test result report&lt;/strong&gt; 添加 &lt;code&gt;nosetests.xml&lt;/code&gt; 显示单元测试的结果。在 Cobertura 插件 &lt;strong&gt;Publish Cobertura Coverage Report&lt;/strong&gt; 里添加 &lt;code&gt;coverage.xml&lt;/code&gt; 显示测试代码覆盖率。在 &lt;strong&gt;Report Violations&lt;/strong&gt; 里添加 &lt;code&gt;pylint.out&lt;/code&gt; 显示代码质量报告。&lt;/p&gt;

&lt;p&gt;最终，运行一次作业之后，Jenkins 将可以得到下图显示的测试报告。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://4.bp.blogspot.com/-f_YtJcTOQ64/T5qnlOiE35I/AAAAAAAAAF8/l5Nl_YvRSuM/s1600/jenkins+after+logout+added.png&#34; alt=&#34;Jenkins Output&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;持续整合:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;持续整合！&lt;/h3&gt;

&lt;p&gt;我们持续整合的大致流程是这样的。在代码库中有一个 Master 分支，开发人员添加新功能，修复 Bug 都需要在新建的分支里进行。每新建一个合并到到 Master 的 Pull Request 时，Jenkins 可以自动运行测试。测试通过则在 Bitbucket 的 Pull Request 页面里添加一个的评论表示可以合并，否则会添加一个否决的评论。这个项目的目标就是再添加一个关于测试覆盖率的评论。&lt;/p&gt;

&lt;p&gt;我们按照 &lt;em&gt;Automated python unit testing, code coverage and code quality analysis with Jenkins&lt;/em&gt; 一文的思路实现了测试覆盖率的部分，区别是我们的代码库里包括 Java 和 Python 两种语言的代码，需要同时处理两份数据。经过一段时间的攻关之后，我们终于可以得到代码覆盖的数据。&lt;/p&gt;

&lt;p&gt;相较于测试覆盖率的具体数值，我们更关心覆盖率的变化值。我们希望知道合并一个分支之后，测试覆盖率是增加了还是减少了。因此，现在我们需要得到测试覆盖率的变化值（Coverage diff）。&lt;/p&gt;

&lt;p&gt;没想到 Python 连这种冷僻的使用场景都有第三方的库支持，还不只一个。我们使用的是 &lt;a href=&#34;https://github.com/SurveyMonkey/pycobertura&#34;&gt;Pycobertura&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Pycobertura 可以直接比较两个 Cobertura 格式的 xml 文件，从而得到覆盖率的变化值。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from pycobertura import Cobertura
from pycobertura import TextReporterDelta

coverage1 = Cobertura(&#39;coverage1.xml&#39;)
coverage2 = Cobertura(&#39;coverage2.xml&#39;)
delta = TextReporterDelta(coverage1, coverage2)
delta.generate()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;于是，我创建了一个 Fabric Task，调用 Pycobertura 分析测试生成的 xml 文件和 Master branch 的 xml 文件。在 Jenkins 里添加一段 &lt;strong&gt;Post build script&lt;/strong&gt; 来运行 Fabric，这样 Build 完成之后就可以运行 Fabric 程序得到类似下面的输出结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Coverage Diff for Java code:
No coverage diff can be found.
Coverage Diff for Python code:
Name          Stmts    Miss    Cover
------------  -------  ------  --------
dummy/dummy   -        -2      +50.00%
dummy/dummy2  +2       -       +100.00%
TOTAL         +2       -2      +50.00%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后剩下的就是把之前一步的结果以评论的形式发布到 Bitbucket 里。这里，我们又添加了一个 Fabric 的 Task，通过调用 Bitbucket 的 API 把得到的结果发布到 Pull Request 的页面里。&lt;/p&gt;

&lt;h3 id=&#34;参考文献:fc2286d3c2ea2f10cc076fd6905b3f97&#34;&gt;参考文献&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://bhfsteve.blogspot.com/2012/04/automated-python-unit-testing-code_27.html&#34;&gt;Automated python unit testing, code coverage and code quality analysis with Jenkins - part 3&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>使用 Fabric 进行远程操作</title>
            <link>http://yumminhuang.github.io/blog/2015/04/16/%E4%BD%BF%E7%94%A8-fabric-%E8%BF%9B%E8%A1%8C%E8%BF%9C%E7%A8%8B%E6%93%8D%E4%BD%9C/</link>
            <pubDate>Thu, 16 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/16/%E4%BD%BF%E7%94%A8-fabric-%E8%BF%9B%E8%A1%8C%E8%BF%9C%E7%A8%8B%E6%93%8D%E4%BD%9C/</guid>
            <description>

&lt;h2 id=&#34;fabric-简介:900de048502f7d5abcf000aa59dbd264&#34;&gt;Fabric 简介&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.fabfile.org&#34;&gt;Fabric&lt;/a&gt; 是一个实现远程操作和部署的 Python 模块。Fabric 主要用来作为 SSH 的替代，实现一些简单的应用部署和系统管理。&lt;/p&gt;

&lt;h3 id=&#34;使用-fabric-的好处:900de048502f7d5abcf000aa59dbd264&#34;&gt;使用 Fabric 的好处&lt;/h3&gt;

&lt;p&gt;个人觉得，Fabric 非常适合简单的、重复性的远程操作。&lt;/p&gt;

&lt;p&gt;首先，Fabric 可以使用 Python，比 Shell 要强大、灵活。&lt;/p&gt;

&lt;p&gt;再者，Fabric 避免远程登录，可以把远程操作放在本地运行。&lt;/p&gt;

&lt;p&gt;最后，Fabric 非常简单，只需要编写一个 &lt;code&gt;fabfile.py&lt;/code&gt;（或者像 Python 那样 &lt;a href=&#34;http://docs.fabfile.org/en/latest/usage/fabfiles.html&#34;&gt;导入包来添加更多的功能&lt;/a&gt;），就可以使用&lt;a href=&#34;http://docs.fabfile.org/en/latest/usage/fab.html&#34;&gt;&lt;code&gt;fab&lt;/code&gt; 指令&lt;/a&gt; 运行了。这比 Salt、Chef 等工具轻量，更加容易上手。&lt;/p&gt;

&lt;p&gt;基本上，代码部署，文件修改，远程执行等操作都可以使用 Fabric。&lt;/p&gt;

&lt;h2 id=&#34;常用的-fabric-函数:900de048502f7d5abcf000aa59dbd264&#34;&gt;常用的 Fabric 函数&lt;/h2&gt;

&lt;p&gt;这里简单地介绍 Fabric 里常用的函数，具体的说明请参见 &lt;a href=&#34;http://docs.fabfile.org/en/latest/index.html&#34;&gt;官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;常用操作:900de048502f7d5abcf000aa59dbd264&#34;&gt;常用操作&lt;/h2&gt;

&lt;p&gt;Fabric 的常用 &lt;a href=&#34;http://docs.fabfile.org/en/latest/api/core/operations.html&#34;&gt;操作&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;run&lt;/code&gt;：在远程机器上执行 Shell 命令；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo&lt;/code&gt;：带有 root 权限的 &lt;code&gt;run&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;local&lt;/code&gt;：执行本地命令；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get&lt;/code&gt;：从远程机器下载文件；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;put&lt;/code&gt;：上传文件到远程机器；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prompt&lt;/code&gt;：可以理解为在远程机器上执行 &lt;code&gt;raw_input&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reboot&lt;/code&gt;：重启远程机器。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;常用上下文管理器和装饰器:900de048502f7d5abcf000aa59dbd264&#34;&gt;常用上下文管理器和装饰器&lt;/h3&gt;

&lt;p&gt;上下文管理器（Context Manager）和装饰器（Decorators）是 Python 中的常用的 &lt;a href=&#34;http://zh.wikipedia.org/wiki / 语法糖&#34;&gt;「语法糖（Syntax sugar）」&lt;/a&gt;。Fabric 中常用的&lt;a href=&#34;http://docs.fabfile.org/en/latest/api/core/context_managers.html&#34;&gt;上下文管理器&lt;/a&gt; 有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cd&lt;/code&gt;：切换目录；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lcd&lt;/code&gt;：在本地切换目录，即 &lt;code&gt;local cd&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;path&lt;/code&gt;：可以添加路径到 &lt;code&gt;PATH&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;settings&lt;/code&gt;：用来临时修改 &lt;code&gt;env&lt;/code&gt; 变量，使变量只作用在一段代码中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;常用的 &lt;a href=&#34;http://docs.fabfile.org/en/latest/api/core/decorators.html&#34;&gt;装饰器&lt;/a&gt; 有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@task&lt;/code&gt;：用来把一个函数声明为 &lt;a href=&#34;http://docs.fabfile.org/en/latest/usage/tasks.html&#34;&gt;Fabric Task&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@hosts&lt;/code&gt;：用来制定远程操作的目标机器；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@with_settings&lt;/code&gt;：用来临时设定 &lt;code&gt;env&lt;/code&gt; 变量，可以等同于 &lt;code&gt;with settings&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fabric Task 是我个人非常喜欢的功能。定义一个 Task 之后就可以直接使用 &lt;code&gt;fab task_name&lt;/code&gt; 来执行了。&lt;/p&gt;

&lt;h2 id=&#34;一个例子:900de048502f7d5abcf000aa59dbd264&#34;&gt;一个例子&lt;/h2&gt;

&lt;p&gt;在实习当中，我做了一个工具用来自动备份 AWS EBS Volume。程序运行在远程服务器上。每天早上，我都要检查一下日志文件，看看程序有没有出错。&lt;/p&gt;

&lt;p&gt;开始，我检查的方式是使用 &lt;code&gt;ssh&lt;/code&gt; 登陆之后，再使用 &lt;code&gt;grep&lt;/code&gt; 检查日志文件是否包含 &lt;code&gt;ERROR&lt;/code&gt;、&lt;code&gt;WARNING&lt;/code&gt; 等关键字。后来，我发现检查日志文件的操作都是一些重复操作，于是就写了一个 Bash 脚本来进行检查。这样，每天检查的过程就是使用 &lt;code&gt;ssh&lt;/code&gt; 登陆，再运行脚本进行检查。&lt;/p&gt;

&lt;p&gt;但是，这样检查日志还是有一些麻烦，这促使我转而使用 Fabric。第一，每天都需要远程登录。使用 Fabric 可以直接在本地运行。第二，因为日志每天晚上会回滚，我不仅要检查当天的日志文件，还要检查昨天的日志来确保昨天下班之后程序没有出问题，而日志的名称会随着日期变化。在 Bash 里计算日期是一件相当麻烦的事情。但是，使用 Fabric 之后，因为可以利用 Python 的 &lt;code&gt;datetime&lt;/code&gt;，计算日期就变得非常容易了。下面就是用来检查日志是否包含关键字的函数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from fabric.api import *

def check_log_with_keyword(log_file, keyword):
    with settings(hide(&#39;warnings&#39;,&#39;output&#39;),
                  host_string=&#39;eb101.ops&#39;,
                  warn_only=True):
        result = run(&#39;grep %s %s&#39; % (keyword, filename))

        if result.return_code == 0:
            print(result)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;with settings()&lt;/code&gt; 来临时更改 &lt;code&gt;env&lt;/code&gt; 变量；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hide(&#39;warnings&#39;, &#39;output&#39;)&lt;/code&gt; 可以设置 Fabric 输出（不是远程执行的指令的输出），隐藏 &lt;code&gt;stderr&lt;/code&gt; 和 &lt;code&gt;stdout&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host_string=&#39;eb101.ops&#39;&lt;/code&gt;，设定目标机器，Fabric 可以使用 &lt;code&gt;.ssh/config&lt;/code&gt; 的设置；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;warn_only=True&lt;/code&gt; 用来确保 Fabric 程序不会因为 &lt;code&gt;grep&lt;/code&gt; 指令出错而退出（grep 没找到匹配内容时，返回值是 1）；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;result = run(&#39;grep %s %s&#39; % (keyword, filename))&lt;/code&gt;, 运行 &lt;code&gt;grep&lt;/code&gt; 指令并得到结果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;远程检查日志的过程很简单，并且是机械而重复的过程，因此非常适合使用 Fabric。&lt;/p&gt;

&lt;h3 id=&#34;参考文献:900de048502f7d5abcf000aa59dbd264&#34;&gt;参考文献&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-use-fabric-to-automate-administration-tasks-and-deployments&#34;&gt;How To Use Fabric To Automate Administration Tasks And Deployments&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>Graphite 和 Grafana 简介</title>
            <link>http://yumminhuang.github.io/blog/2015/04/08/graphite-%E5%92%8C-grafana-%E7%AE%80%E4%BB%8B/</link>
            <pubDate>Wed, 08 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/08/graphite-%E5%92%8C-grafana-%E7%AE%80%E4%BB%8B/</guid>
            <description>

&lt;h2 id=&#34;graphite:b7837abce316965fc5b3c43248c541ea&#34;&gt;Graphite&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://graphite.wikidot.com/start&#34;&gt;Graphite&lt;/a&gt; 是一款开源的监控绘图工具。&lt;/p&gt;

&lt;p&gt;Graphite 可以实时收集、存储、显示时间序列类型的数据（time series data）。它主要有三个部分构成：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/graphite-project/carbon&#34;&gt;carbon&lt;/a&gt;&lt;/strong&gt; —— 基于 &lt;a href=&#34;https://twistedmatrix.com/trac/&#34;&gt;Twisted&lt;/a&gt; 的进程，用来接收数据；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/graphite-project/whisper&#34;&gt;whisper&lt;/a&gt;&lt;/strong&gt; —— 专门存储时间序列类型数据的小型数据库；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/graphite-project/graphite-web&#34;&gt;graphite webapp&lt;/a&gt;&lt;/strong&gt; —— 基于 Django 的网页应用程序。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/graphite-project/graphite-web/master/webapp/content/img/overview.png&#34; alt=&#34;Graphite Overview&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;向graphite发送数据:b7837abce316965fc5b3c43248c541ea&#34;&gt;向Graphite发送数据&lt;/h3&gt;

&lt;p&gt;Graphite 的使用非常简单。我们可以定义一个被观测量（Metric）。Metric 使用键／值的数据类型。只要不断发送&lt;code&gt;观测量: 观测值&lt;/code&gt;这一键值组合，就可以得到以时间为X轴，观测值为 Y 轴的图。&lt;/p&gt;

&lt;p&gt;当我们使用诸如 collectd、Sensu 之类的工具收集到数据之后，只需要向 Graphite 的服务器发送以下格式的 TCP 报文即可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;metric name&amp;gt; &amp;lt;metric value&amp;gt; &amp;lt;metric timestamp&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如，有一个 Metric 叫作 &lt;code&gt;local.metric.random&lt;/code&gt;，可以用下面的 Bash 命令发送当前时刻的值 &lt;code&gt;4&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PORT=2003
SERVER=graphite.your.org
echo &amp;quot;local.metric.random 4 `date +%s`&amp;quot; | nc -q0 ${SERVER} ${PORT}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;类似地，使用其它编程语言时，可以使用 Socket 发送数据。&lt;/p&gt;

&lt;p&gt;另外，Graphite 的 Metric 名称支持以 &lt;code&gt;.&lt;/code&gt; 作为分隔符的多级嵌套。例如我可以定义下面三个 Metric。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;webserver.system.cpu_usage&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;webserver.system.mem_load&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;webserver.network.input&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Graphite 将以树型结构展示这三个 Metric。因此，使用 Graphite 的第一步就是给 Metric 选取一个合适的名称。关于如何组织 Metric 的名称，可以参阅文章 &lt;a href=&#34;http://matt.aimonetti.net/posts/2013/06/26/practical-guide-to-graphite-monitoring/&#34;&gt;Practical Guide to StatsD/Graphite Monitoring&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;graphite-event:b7837abce316965fc5b3c43248c541ea&#34;&gt;Graphite Event&lt;/h3&gt;

&lt;p&gt;除了支持简单的键／值数据类型，Graphite 还可以通过 &lt;a href=&#34;http://graphite.readthedocs.org/en/1.0/functions.html#graphite.render.functions.events&#34;&gt;Events&lt;/a&gt; 来存储更复杂的数据。简而言之，Graphite Events 使用了 &lt;code&gt;tag&lt;/code&gt; 和 &lt;code&gt;data&lt;/code&gt; 两个键来存储更多的信息。&lt;/p&gt;

&lt;p&gt;我们可以使用 HTTP POST 向 Graphite 发送一个 Event。&lt;/p&gt;

&lt;p&gt;```curl -X POST &amp;ldquo;&lt;a href=&#34;http://graphite.your.org/events&amp;quot;&#34;&gt;http://graphite.your.org/events&amp;quot;&lt;/a&gt; -d &amp;lsquo;{&amp;ldquo;what&amp;rdquo;: &amp;ldquo;Deployment&amp;rdquo;, &amp;ldquo;tags&amp;rdquo;: &amp;ldquo;webserver&amp;rdquo;, &amp;ldquo;data&amp;rdquo;: &amp;ldquo;Deploy webserver&amp;rdquo;}&amp;rsquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
下文将会通过一个具体的实例来介绍Events的使用场景。

## Grafana

鉴于 Graphite 的界面过于简单，功能比较单一，可以使用 [Grafana](http://grafana.org/) 作为 Graphite 的控制台。 Grafana 是一款开源的图形控制台，有很多[不错的特性](http://grafana.org/features)，还可以访问官网提供的 [Live Demo](http://play.grafana.org) 来体验 Grafana。

设置 Grafana，只需编辑 `config.js` 设置数据来源[^update]。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;datasources: {
  graphite: {
    type: &amp;lsquo;graphite&amp;rsquo;,
    url: &amp;ldquo;&lt;a href=&#34;http://my.graphite.server.com:8080&amp;quot;&#34;&gt;http://my.graphite.server.com:8080&amp;quot;&lt;/a&gt;,
  }
},&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
具体的配置教程可以参见[官方文档](http://docs.grafana.org/v1.9/installation/)。

## 实例

我实习所在公司使用 [Jenkins](https://jenkins-ci.org) 部署代码。在部署完成之后，我添加了一段 [post-build script](https://wiki.jenkins-ci.org/display/JENKINS/PostBuildScript+Plugin) 执行下面的脚本。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#!/bin/bash&lt;/p&gt;

&lt;p&gt;HOST=&lt;a href=&#34;http://graphite.your.org/events&#34;&gt;http://graphite.your.org/events&lt;/a&gt;
echo &amp;lsquo;Posting a deployment event to Graphite&amp;rsquo;
curl -X POST $HOST -d &amp;lsquo;{&amp;ldquo;what&amp;rdquo;: &amp;ldquo;Deployment&amp;rdquo;, &amp;ldquo;tags&amp;rdquo;: &amp;ldquo;webserver,prd&amp;rdquo;, &amp;ldquo;data&amp;rdquo;: \&amp;ldquo;$BUILD_URL\&amp;ldquo;}&amp;rsquo;
```&lt;/p&gt;

&lt;p&gt;这样，每次部署完成之后都会发送一个 Deployment Event 到 Graphite。接着，可以在 Graphite 里添加 &lt;code&gt;drawAsInfinite(events(&#39;prd&#39;))&lt;/code&gt; 或者在 Grafana 里使用 &lt;a href=&#34;http://grafana.org/docs/features/annotations/&#34;&gt;Annotations Page&lt;/a&gt; 来绘制一幅图显示代码部署的 Events。&lt;/p&gt;

&lt;p&gt;利用 Graphite Events 和 Metrics，我们可以将代码部署和其他指征叠加在一幅图里，从而分析每次代码部署和其它指征的关系。&lt;/p&gt;

&lt;p&gt;比如，在 &lt;em&gt;Tracking Every Release&lt;/em&gt; 一文中，作者使用了该方法将 &lt;code&gt;PHP Warning&lt;/code&gt; 和 &lt;code&gt;Code deploy&lt;/code&gt; 叠加在一幅图里。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://codeascraft.com/wp-content/uploads/2010/12/warnings_1hr_deploys3.png&#34; alt=&#34;Track Release&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从图中，我们可以发现第一次代码部署之后导致了大量的警告信息，经过随后的两次 Hotfix 之后，警告信息基本消除。&lt;/p&gt;

&lt;h2 id=&#34;总结:b7837abce316965fc5b3c43248c541ea&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文非常简要地介绍了 Graphite 和 Grafana 的一些特性和使用场景。我也是在实习当中第一次接触到这两个工具，很多具体的细节还在摸索之中。&lt;/p&gt;

&lt;p&gt;总之，Graphite 是一个易扩展，使用简便的监控绘图工具，在这里推荐给大家使用。&lt;/p&gt;

&lt;h2 id=&#34;参考文献:b7837abce316965fc5b3c43248c541ea&#34;&gt;参考文献&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://obfuscurity.com/2014/01/Graphite-Tip-A-Better-Way-to-Store-Events&#34;&gt;Graphite Tip - A Better Way to Store Events&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codeascraft.com/2010/12/08/track-every-release/&#34;&gt;Tracking Every Release&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://joshhertz.se/post/making-annotations-in-graphana&#34;&gt;Making Annotations in Graphana&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>Sensu 简介</title>
            <link>http://yumminhuang.github.io/blog/2015/04/04/sensu-%E7%AE%80%E4%BB%8B/</link>
            <pubDate>Sat, 04 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/04/sensu-%E7%AE%80%E4%BB%8B/</guid>
            <description>

&lt;h2 id=&#34;sensu-简介:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu 简介&lt;/h2&gt;

&lt;p&gt;Sensu 是一款开源的监控框架。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://sensuapp.org/docs/0.16/img/sensu-diagram-87a902f0.gif&#34; alt=&#34;Sensu components&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Sensu 采用 C/S 结构，有用来发送指令、存储数据的 Sensu Server 和被监控的对象 Sensu Client。Sensu Server 和 Sensu Client 之间使用 RabbitMQ 进行通信，Server 端使用 Redis 存储数据。每一个 Sensu Client 使用 JSON 进行设置。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;client&amp;quot;: {
    &amp;quot;name&amp;quot;: &amp;quot;i-424242&amp;quot;,
    &amp;quot;address&amp;quot;: &amp;quot;127.0.0.1&amp;quot;,
    &amp;quot;subscriptions&amp;quot;: [
      &amp;quot;production&amp;quot;,
      &amp;quot;webserver&amp;quot;
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，&lt;code&gt;subscriptions&lt;/code&gt; 指定了 Sensu Client 订阅哪些监控项目。 Sensu 采用了&lt;a href=&#34;http://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern&#34;&gt;订阅者模式&lt;/a&gt;，相应地，定义监控项目的时候则需要指定 &lt;code&gt;subscribers&lt;/code&gt;（后文中将会提及）。&lt;/p&gt;

&lt;h3 id=&#34;sensu-的优势:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu 的优势&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;纯 Ruby 实现，核心代码不超过 1000 行；&lt;/li&gt;
&lt;li&gt;配置简单，配置文件使用 JSON；&lt;/li&gt;
&lt;li&gt;结构简单，易扩展，很容易就能够上手编写插件；&lt;/li&gt;
&lt;li&gt;丰富的社区支持，&lt;a href=&#34;https://github.com/sensu/sensu-community-plugins&#34;&gt;Sensu Community Plugin&lt;/a&gt; 几乎包含了所有常用的监控项目。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;sensu-的结构:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu 的结构&lt;/h3&gt;

&lt;p&gt;简单来说，Sensu 分为 Check 和 Handler 两个部分。Sensu 经常被描述为「monitoring router」，因为它不仅可以用 Check 监控系统，还可以设置 Handler 根据当前的条件采取相应的行动。&lt;/p&gt;

&lt;h4 id=&#34;sensu-check:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu Check&lt;/h4&gt;

&lt;p&gt;Sensu Check 用来监控服务和资源。Check 由 Sensu Server 发出执行指令后在 Sensu Client 上运行。本质上，Sensu Check 是一个命令或者脚本，用来把数据输出到 &lt;code&gt;STDOUT&lt;/code&gt; 或者 &lt;code&gt;STDERR&lt;/code&gt;；同时，用返回值（exit status code）来指示状态：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;0&lt;/code&gt;： OK&lt;/li&gt;
&lt;li&gt;&lt;code&gt;1&lt;/code&gt;：WARNING&lt;/li&gt;
&lt;li&gt;&lt;code&gt;2&lt;/code&gt;：CRITICAL&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;gt;3&lt;/code&gt;：UNKNOWN or CUSTOM&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，只要定义好返回值和输出，很容易就可以写出一个 Sensu Check。下面就是一个用来监测 &lt;code&gt;chef-client&lt;/code&gt; 进程是否在运行的 Ruby 脚本。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;procs = `ps aux`
  running = false
  procs.each_line do |proc|
    running = true if proc.include?(&#39;chef-client&#39;)
  end
  if running
    puts &#39;OK - Chef client daemon is running&#39;
    exit 0
  else
    puts &#39;WARNING - Chef client daemon is NOT running&#39;
    exit 1
  end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;写好一个Check的脚本，需要在配置文件中添加它。比如下面,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;checks&amp;quot;: {
    &amp;quot;chef_client&amp;quot;: {
      &amp;quot;command&amp;quot;: &amp;quot;check-chef-client.rb&amp;quot;,
      &amp;quot;subscribers&amp;quot;: [
        &amp;quot;production&amp;quot;
      ],
      &amp;quot;interval&amp;quot;: 60,
      &amp;quot;handlers&amp;quot;: [
        &amp;quot;pagerduty&amp;quot;,
        &amp;quot;mail&amp;quot;
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;subscribers&lt;/code&gt; 用来指定订阅者。&lt;code&gt;interval&lt;/code&gt; 定义检查的周期为 &lt;code&gt;60s&lt;/code&gt;，&lt;code&gt;handlers&lt;/code&gt; 则告诉 Sensu 当此 Check 出现异常时使用 &lt;code&gt;pagerduty&lt;/code&gt; 和 &lt;code&gt;mail&lt;/code&gt; 这两个 Handler。&lt;/p&gt;

&lt;h4 id=&#34;sensu-handler:b6bdba0566435a1fdf738209881f4749&#34;&gt;Sensu Handler&lt;/h4&gt;

&lt;p&gt;Sensu Handler 用来处理 Sensu Check 产生的 Event，例如发送邮件通知，将采集的数据发送到 &lt;a href=&#34;http://graphite.wikidot.com&#34;&gt;Graphite&lt;/a&gt;，等等。 Handler 有不同的类型，有常用的 &lt;code&gt;Pipe&lt;/code&gt;，可以将 Event 传入到 &lt;code&gt;STDIN&lt;/code&gt;（可以理解为 &lt;code&gt;cat event.json | handler&lt;/code&gt;）；有 TCP/UDP，将 Event 传入到 Socket 发送。&lt;/p&gt;

&lt;p&gt;下面是一个简单的 Sensu Handler 定义，用来将 Event 的内容发送到指定的邮箱地址。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;handlers&amp;quot;: {
    &amp;quot;mail&amp;quot;: {
      &amp;quot;type&amp;quot;: &amp;quot;pipe&amp;quot;,
      &amp;quot;command&amp;quot;: &amp;quot;mailx -s &#39;sensu event&#39; email@address.com&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;基于-sensu-的安全更新监控工具:b6bdba0566435a1fdf738209881f4749&#34;&gt;基于 Sensu 的安全更新监控工具&lt;/h2&gt;

&lt;p&gt;接下来，结合我这次实习里的一个项目来详细地介绍一下 Sensu 的使用。&lt;/p&gt;

&lt;h3 id=&#34;需求:b6bdba0566435a1fdf738209881f4749&#34;&gt;需求&lt;/h3&gt;

&lt;p&gt;我们公司在 AWS 上有大约350个实例&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:b6bdba0566435a1fdf738209881f4749:Instance&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:b6bdba0566435a1fdf738209881f4749:Instance&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，运行的是 Ubuntu 操作系统。服务器上的软件会不定期收到更新，包括非常重要的安全更新。我们希望及时知道服务器上有哪些安全更新可以安装，最好可以通过邮件的方式通知。通知里应当至少包括如下信息：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;更新的软件包名称；&lt;/li&gt;
&lt;li&gt;软件包当前的版本；&lt;/li&gt;
&lt;li&gt;可供安装的版本。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;此外，一个邮件里包含 350 台机器的信息显然不方便阅读。恰好公司的 350 台服务器根据功能分为若干个 &lt;code&gt;subnet&lt;/code&gt;，如 dev，tst，stg 等。所以，最好可以为每一个 subnet 生成一份安全更新的报告。&lt;/p&gt;

&lt;h3 id=&#34;实现:b6bdba0566435a1fdf738209881f4749&#34;&gt;实现&lt;/h3&gt;

&lt;h4 id=&#34;安全更新的信息收集:b6bdba0566435a1fdf738209881f4749&#34;&gt;安全更新的信息收集&lt;/h4&gt;

&lt;p&gt;使用 Debian/Ubuntu 的用户都知道，每次登陆都会看到类似的信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;17 packages can be updated.
6 updates are security updates.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以此为源头，我找到了 Debian 系统内自带的一个 Python 脚本 &lt;code&gt;/usr/lib/update-notifier/apt_check.py&lt;/code&gt;。它可以调用 &lt;a href=&#34;https://apt.alioth.debian.org/python-apt-doc/index.html&#34;&gt;python-apt&lt;/a&gt; 库收集系统当前可以安装的安全更新。以此脚本为基础稍加改动就可以得到我们所需要的信息。&lt;/p&gt;

&lt;p&gt;我已经把修改过的脚本做成了一个 &lt;a href=&#34;https://github.com/sensu/sensu-community-plugins/blob/master/plugins/system/package-updates-metric.py&#34;&gt;Sensu Plugin&lt;/a&gt; 提交到了 Sensu 社区。&lt;/p&gt;

&lt;p&gt;####信息的汇集和通知
第一步非常顺利，但是还有问题需要解决：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Python 脚本只能收集本地的信息，如何把350台服务器的信息汇集在一起？&lt;/li&gt;
&lt;li&gt;信息汇集完了如何进行分类、通知？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;为了解决这两个问题，就需要用到本文的主角 Sensu  了。&lt;/p&gt;

&lt;p&gt;第一个问题是汇集多台机器的检查结果。事实上，通常的Sensu Check 也只能检查一台机器。为了解决第一个问题，我使用了 &lt;a href=&#34;http://sensuapp.org/docs/0.16/api_aggregates&#34;&gt;Sensu Aggregate API&lt;/a&gt;。我们可以把一个 Sensu Check 定义成 &lt;a href=&#34;http://sensuapp.org/docs/0.16/checks&#34;&gt;Aggregate Check&lt;/a&gt;，然后通过 API 可以得到所有该 Check 的结果。&lt;/p&gt;

&lt;p&gt;因此，整个安全更新监控工具使用了两个 Sensu Check。第一个 Aggregate Check 运行在所有的服务器上，用来收集本地的安全更新。第二个 Check 运行在一台服务器上，它会调用 Aggregate API 读取第一个 Check 的结果，再加以归类、分析。如果有安全更新可以安装，就触发 Handler 发送通知邮件。&lt;/p&gt;

&lt;p&gt;第一个 Check 的定义：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;checks&amp;quot;: {
    &amp;quot;apt-check&amp;quot;: {
      &amp;quot;command&amp;quot;: &amp;quot;package-updates-metric.py&amp;quot;,
      &amp;quot;subscribers&amp;quot;: [
        &amp;quot;production&amp;quot;
      ],
      &amp;quot;interval&amp;quot;: 28800,
      &amp;quot;aggregate&amp;quot;: true,
      &amp;quot;handler&amp;quot;: false
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第二个Check的定义：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;checks&amp;quot;: {
    &amp;quot;aggregate_apt_check&amp;quot;: {
      &amp;quot;command&amp;quot;: &amp;quot;package-updates-check.py&amp;quot;,
      &amp;quot;subscribers&amp;quot;: [
        &amp;quot;mg102.ops&amp;quot;
      ],
      &amp;quot;publish&amp;quot;: false,
      &amp;quot;handler&amp;quot;: &amp;quot;package-updates-notify.rb&amp;quot;,
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，&lt;code&gt;package-updates-check.py&lt;/code&gt; 是另外一个 Python 脚本，主要是访问 API 并且读取结果。如果发现了安全更新就输出结果并返回&lt;code&gt;1&lt;/code&gt;，这样就可以触发 &lt;code&gt;package-updates-notify.rb&lt;/code&gt;。这是一个 Ruby 脚本，用来读取第二个 Check 的结果，再把结果分成不同的 subnet 发送邮件。
另外，这里设置了 &lt;code&gt;&amp;quot;publish&amp;quot;: false&lt;/code&gt;，所以这个 Check 需要手工启动（因为没有必要定时调用，每天一次足矣），可以通过以下命令来手动请求 Sensu Check。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -XPOST http://api.sensu.example.com:4567/check/request -d &#39;{&amp;quot;check&amp;quot;:&amp;quot;aggregate_apt_check&amp;quot;}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我添加了一个 Cron job 每天早上定时调用该命令。这样每天早上一到办公室就可以及时获知所有服务器是否需要更新。&lt;/p&gt;

&lt;p&gt;整个工具就基本完成了。剩下的内容就是写一个 Chef 的 Recipe，把工具部署到所有的服务器上。&lt;/p&gt;

&lt;h3 id=&#34;总结:b6bdba0566435a1fdf738209881f4749&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;这就是我的第一个 Sensu 项目。学习一门编程语言或一个工具最好的方法就是用它来做一个项目。的确，通过这个项目让我对 Sensu 的功能和特性有了比较清楚的了解。&lt;/p&gt;

&lt;p&gt;整个安全更新监控工具的实现描述得很简单，但是从立项到投入实际应用还是用了我一个月的时间，后期还花费了一些时间在修复 Bug 上。因为很多工具都是初次使用，包括第一次接触 Sensu，第一次使用 Ruby 做项目，第一次使用 Chef，实现的过程中边学边做，还是走了不少弯路。&lt;/p&gt;

&lt;p&gt;本文里只列出大致的框架，有一些代码没有贴出，贴出的代码也非完全准确。但是思路和意思已经都展现清楚了。&lt;/p&gt;

&lt;p&gt;更加详细的内容可以参阅 &lt;a href=&#34;http://sensuapp.org/docs/0.16/overview&#34;&gt;Sensu 文档&lt;/a&gt;。&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:b6bdba0566435a1fdf738209881f4749:Instance&#34;&gt;「实例」（Instance）这个说法听上去非常别扭，若无特别说明下文中「服务器」即指 AWS 实例。
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:b6bdba0566435a1fdf738209881f4749:Instance&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>3 个月运维工作之总结</title>
            <link>http://yumminhuang.github.io/blog/2015/04/01/3-%E4%B8%AA%E6%9C%88%E8%BF%90%E7%BB%B4%E5%B7%A5%E4%BD%9C%E4%B9%8B%E6%80%BB%E7%BB%93/</link>
            <pubDate>Wed, 01 Apr 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/04/01/3-%E4%B8%AA%E6%9C%88%E8%BF%90%E7%BB%B4%E5%B7%A5%E4%BD%9C%E4%B9%8B%E6%80%BB%E7%BB%93/</guid>
            <description>&lt;p&gt;自从 1 月 5 日开始实习至今，在 Operation Team 已经工作了三个月。我觉得有必要对工作进行一下总结。既是我对三个月来所学新知识的归纳，也是对运维工作的一些思考。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;这次实习并非是我第一次接触运维工作。2014 年夏天，我有一份两个月的暑期实习。当时实习工作的职位是 *Backend Software Engineer*，但事实上所完成的绝大部分工作的内容是关于运维，主要有 &lt;a href=&#34;http://aws.amazon.com/autoscaling/&#34;&gt;AWS Auto Scaling&lt;/a&gt; 的搭建（关于这部分内容可以参见之前的一篇 &lt;a href=&#34;http://yumminhuang.github.io/zai-aws-auto-scaling-group-zhong-ti-huan-instance.html&#34;&gt;博文&lt;/a&gt;）和基于 &lt;a href=&#34;http://aws.amazon.com/cloudwatch/&#34;&gt;AWS Cloudwatch&lt;/a&gt; 实现一些监测工具。所以也算对运维工作有一些经验。之后在找实习的时候，我也是有意识地找运维相关的职位。&lt;/p&gt;

&lt;p&gt;这里也顺便说一下暑期实习的公司。那是一个只有 5、6 个程序员的初创公司。公司所有的服务都搭建在 Amazon Web Service。运维可以说略显「简陋」：服务器的操作全部由 Python 脚本实现；代码的部署也是用 Python 脚本从 svn 下载再进行安装；系统监控全部部署在 Cloudwatch。对于只有十多台服务器的公司来说，这样的运维方法似乎也足够了。&lt;/p&gt;

&lt;p&gt;所以在这次实习之前，我对运维工作的印象还是停留在启动、监控、维护服务器，写一些脚本来实现自动化，最多在服务器出问题的时候做一下 &lt;a href=&#34;http://en.wikipedia.org/wiki/Hotfix&#34;&gt;Hotfix&lt;/a&gt;。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;但是当服务器数量到达几百台的时候，显然之前实习中所用的方法是不够的。这次实习所在公司的规模要比之前大得多，在 AWS 上大约有 350 台实例。因此接触到了更加专业的运维工具、工作方法和流程，对运维工作也有了更加深刻的认识。&lt;/p&gt;

&lt;p&gt;先说工具的使用。和开发、测试不同的是，运维工作会接触到各种工具，最近几个月接触到的工具包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自动化部署工具 &lt;a href=&#34;https://www.chef.io/chef/&#34;&gt;Chef&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Continuous_integration&#34;&gt;持续集成（CI）&lt;/a&gt; 工具 &lt;a href=&#34;https://jenkins-ci.org/&#34;&gt;Jenkins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;监控框架 &lt;a href=&#34;http://sensuapp.org/&#34;&gt;Sensu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;数据绘图工具 &lt;a href=&#34;http://graphite.wikidot.com/&#34;&gt;Graphite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;代码质量管理系统 &lt;a href=&#34;http://www.sonarqube.org/&#34;&gt;SonarQube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最让我印象深刻的应该是 Jenkins，第一次见识到自动化 CI 的感觉大概就和当年用了一学期 Turbo C 后第一次见到 Eclipse 一样。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://media.tumblr.com/fe40a2da7c8e594479f48fd8450817d5/tumblr_inline_nczuo9C9ov1raprkq.gif&#34; alt=&#34;Demonstrating end-to-end automation to new employees&#34; /&gt;&lt;/p&gt;

&lt;p&gt;每一个工具都自成体系，组合在一起又成为了相当复杂的运维系统。争取未来一段时间内，写一些文章来总结这些工具。&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;Welcome to Operation team! Every Ops guy has crashed a server.&lt;/p&gt;

&lt;p&gt;&amp;ndash; 工作近一个月，我第一次弄崩服务器程序之后，同事如是说&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;一个体会是运维工作对知识面要求挺高的。要能够编程、测试，因为很多时候要自己实现工具，这个时候要自己编码，自己测试。而且知识点很繁杂，操作系统、网络、软件工程这些学科的知识都会经常使用。&lt;/p&gt;

&lt;p&gt;另一个体会是运维工作不只是管理服务器、部署程序，而是深入到公司开发流程的各个方面。开发人员写的代码需要有工具能够自动运行测试，自动合并到 Master 分支。测试人员做完测试要生成测试覆盖率的报告。还有常规的服务器管理，系统监测，所有这些林林总总的基础设施搭建都需要运维团队来做。就连办公室断了网也是由我们组来处理。&lt;/p&gt;

&lt;p&gt;更为重要的体会还是在于运维工作的方法学方面。总的来说，感觉运维工作在很大程度上要靠经验的积累。下面一些内容未必正确，但都是工作三个月来自己的切身感受。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对系统的熟悉重于对算法的掌握&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;并非算法不重要，而是运维工作更多的时间里是在和 API、工具打交道，需要自己设计算法的场合相对比较少。现在的 API、工具越来越强大，很多复杂的算法都已经被封装起来了，不需要程序员自己来实现。但是，运维工作对系统熟悉的要求比较高。具体来说，你需要清楚地知道当前系统里每个工具做什么，怎么做。对软件工程各个环节中可能用到的工具要有了解，至少知道它能干什么，不能干什么。而且你还要知道不同工具如何配合使用，因为很多任务需要系统内几个工具一起合作。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对一个任务具体过程的熟悉重于对编程细节实现&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一方面，运维工作自身的编程工作一般都比较简单。以部署来说，借助于像 Chef 这样的自动化部署工具，软件包的下载、配置文件的修改等琐碎细节都已经被隐藏，只需要编写脚本定义部署的步骤就可以了。所以在准备部署一个服务的时候，我们不需要知道怎样下载软件包，如何读、写文件，但是要非常清楚地知道搭建这个服务要经过哪几个步骤。有时候甚可能还需要清楚地知道每个步骤的顺序，比如服务的配置需要改变，是先停止程序，还是先修改配置文件。这就要求对每个任务的流程都很熟悉。&lt;/p&gt;

&lt;p&gt;另一方面，运维不像开发那样需要知道公司业务的细节。运维工作是独立于公司业务的，不需要相应的 Domain Knowledge。我至今也不太了解公司核心业务是如何实现的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;成本估算的能力&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;运维工作是以成本为中心的。在公司里不能带来实际的收入，我们需要做的是花尽可能少的钱来提高公司的效率，保证服务的稳定。所以在接手一个任务之前，要估算不同解决方案的成本。有时候遇到一个问题，市场上有现成的收费工具可以用。如果不想花钱，自己来实现需要花费多少时间。&lt;/p&gt;

&lt;p&gt;刚入职时的一个任务是：检查公司里几百台服务器是否有安全更新需要安装，要有通知功能，能够列出有哪些更新，并且支持一键安装。现成的解决方案有针对 Ubuntu 系统的 &lt;a href=&#34;https://landscape.canonical.com/&#34;&gt;Canonical Landscape&lt;/a&gt;。功能齐全，界面美观，但是其价格到了瞠目结舌的地步，每 100 台机器一年要 $75K，难以想象一个 Linux 管理工具卖这么贵会不会有人用。这个成本显然是不能接受的。后来又找到一个独立开发者开发的补丁管理工具 &lt;a href=&#34;https://sysward.com/&#34;&gt;Sysward&lt;/a&gt;，完全符合我们最初的需求，但是估算了一下，用这个每个月的费用仍然有 $700。最后考虑到这个需求并不是非常着急，而且在公司所使用的开源工具的基础上可以做出来，所以决定自己来做这个工具。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上就是实习三个月以来，身为一个运维新人的体会和思考，想法或许还有些不成熟、不准确。实习还有四个月时间结束，希望届时能够有更多的体会可以总结。&lt;/p&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>在 VPS 搭建 VPN 服务器</title>
            <link>http://yumminhuang.github.io/blog/2015/03/16/%E5%9C%A8-vps-%E6%90%AD%E5%BB%BA-vpn-%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
            <pubDate>Mon, 16 Mar 2015 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2015/03/16/%E5%9C%A8-vps-%E6%90%AD%E5%BB%BA-vpn-%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
            <description>

&lt;h2 id=&#34;简介:eb745fd234e99be994e6ebc392359fde&#34;&gt;简介&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;从来就没有什么救世主&lt;/p&gt;

&lt;p&gt;也不靠神仙皇帝&lt;/p&gt;

&lt;p&gt;要创造人类的幸福&lt;/p&gt;

&lt;p&gt;全靠我们自己&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了在 &lt;a href=&#34;http://zh.wikipedia.org/wiki/防火长城&#34;&gt;GFW&lt;/a&gt; 的封锁之下进行正常的上网活动，可以使用 &lt;a href=&#34;http://zh.wikipedia.org/wiki/虛擬私人網路&#34;&gt;VPN&lt;/a&gt;。为什么有各种各样的 VPN 服务提供商还要自己搭建 VPN 呢？有以下几方面的考虑：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;安全性：你很难保证一些 VPN 提供商不会盗取你的敏感信息，自己搭建 VPN 则可以避免这个问题；&lt;/li&gt;
&lt;li&gt;稳定：「道高一尺，魔高一丈」，现在很多 VPN 提供商都是打一枪换一个地方，难以保证稳定的连接；&lt;/li&gt;
&lt;li&gt;价格：自己搭建 VPN，一个月的费用大概在 $5 左右。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;具体步骤:eb745fd234e99be994e6ebc392359fde&#34;&gt;具体步骤&lt;/h2&gt;

&lt;h4 id=&#34;注册一个-vps-账号:eb745fd234e99be994e6ebc392359fde&#34;&gt;注册一个 VPS 账号&lt;/h4&gt;

&lt;p&gt;注册任意一家 VPS 服务提供商的账号。此步可能需要一张双币信用卡。
至于选择哪家服务商，此处按下不表。下文将以 &lt;strong&gt;DigitalOcean&lt;/strong&gt; 为例描述具体步骤。&lt;/p&gt;

&lt;h4 id=&#34;新建一个-droplet:eb745fd234e99be994e6ebc392359fde&#34;&gt;新建一个 Droplet&lt;/h4&gt;

&lt;p&gt;我新建的 Droplet 是最低配置，具体配置包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;512MB RAM&lt;/li&gt;
&lt;li&gt;20GB SSD&lt;/li&gt;
&lt;li&gt;2TB 流量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;地理位置选的是最近的。&lt;/p&gt;

&lt;p&gt;操作系统开始选择的是 Ubuntu14.04，后来用的是 Ubuntu12.04（版本应该没有影响）。&lt;/p&gt;

&lt;p&gt;没有选择多余的设置。&lt;/p&gt;

&lt;p&gt;点击新建按钮会收到一份包含登陆密码的邮件。接着就可以通过ssh进行登录了。&lt;/p&gt;

&lt;p&gt;其余添加用户、Linux 基本设置等内容在此不再赘述。&lt;/p&gt;

&lt;h4 id=&#34;安装pptp:eb745fd234e99be994e6ebc392359fde&#34;&gt;安装PPTP&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install pptpd
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;配置:eb745fd234e99be994e6ebc392359fde&#34;&gt;配置&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;配置 IP 地址&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;编辑 &lt;code&gt;/etc/pptpd.conf&lt;/code&gt;，添加以下内容(基本上默认设置已经完成或者被注释了)：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;option /etc/ppp/pptpd-options
localip 192.168.0.1
remoteip 192.168.0.100-200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里是 PPTP 服务器的 IP 地址设为 &lt;code&gt;192.178.0.1&lt;/code&gt; ，把 PPTP 客户端的 IP 地址设置为 &lt;code&gt;192.168.0.100&lt;/code&gt; 到 &lt;code&gt;192.168.0.200&lt;/code&gt; 的区间内。当然你也可以自己的需要和喜欢进行相应的设置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;配置客户端 DNS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;编辑 &lt;code&gt;/etc/ppp/pptpd-options&lt;/code&gt; ，添加 DNS 地址。这里我选择的是&lt;a href=&#34;https://developers.google.com/speed/public-dns/&#34;&gt;Google Public DNS&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ms-dns 8.8.8.8
ms-dns 8.8.4.4
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;添加用户&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;编辑 &lt;code&gt;/etc/ppp/chap-secrets&lt;/code&gt;，添加账号和密码。其中第一列为账户名，第二列为密码。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# client    server  secret          IP addresses
test		pptpd   1234            *
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;设置 IP 转发&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;打开 IPv4 转发，并重新载入设置。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo sed -i &#39;s/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g&#39; /etc/sysctl.conf
sudo sysctl -p
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为 PPTP 连接设置 NAT，否则不能访问别的网站。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也可以直接编辑 &lt;code&gt;/etc/rc.local&lt;/code&gt;，在 &lt;code&gt;exit 0&lt;/code&gt; 之前添加以上内容。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;重启 PPTP&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo service pptpd restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样PPTP服务器就搭建完毕了，可以「科学上网」了！&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;没有什么能够阻挡&lt;/p&gt;

&lt;p&gt;你对自由地向往&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;trouble-shooting:eb745fd234e99be994e6ebc392359fde&#34;&gt;Trouble Shooting&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;PPTP connection error: GRE: Bad checksum from pppd&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第一次设置完毕之后尝试连接 VPN，发现连接失败。重新设置之后依然没有解决，以至于让我怀疑是 Ubuntu14.04 的问题。我新建了一个 Droplet，更换成 Ubuntu12.04 之后还是同样的问题。接着尝试用&lt;code&gt;netstat&lt;/code&gt;检查，发现连接已经建立，但是因为某种原因被断开了。检查&lt;code&gt;/var/log/syslog&lt;/code&gt;，发现了以下内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Mar 21 16:54:23 Server pptpd[1808]: GRE: Bad checksum from pppd.
Mar 21 16:54:53 Server pppd[1809]: LCP: timeout sending Config-Requests
Mar 21 16:54:53 Server pppd[1809]: Connection terminated.
Mar 21 16:54:53 Server pppd[1809]: Modem hangup
Mar 21 16:54:53 Server pppd[1809]: Exit.
Mar 21 16:54:53 Server pptpd[1808]: GRE: read(fd=6,buffer=80504c0,len=8196) from PTY failed: status = -1 error = Input/output error, usually caused by unexpected termination of pppd, check option syntax and pppd logs
Mar 21 16:54:53 Server pptpd[1808]: CTRL: PTY read or GRE write failed (pty,gre)=(6,7)
Mar 21 16:54:53 Server pptpd[1808]: CTRL: Reaping child PPP[1809]
Mar 21 16:54:53 Server pptpd[1808]: CTRL: Client 50.164.202.163 control connection finished
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上网搜索，在 StackOverflow 上找到了&lt;a href=&#34;http://stackoverflow.com/a/21347817&#34;&gt;答案&lt;/a&gt;。至此，终于定位到无法连接的根本原因 —— 是路由器不支持 &lt;code&gt;PPTP Passthrough&lt;/code&gt; 功能。我上路由器厂商的官网一看，果然发现了去年12月发布了一个固件更新用来修复VPN连接的问题。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;vps服务提供商选择:eb745fd234e99be994e6ebc392359fde&#34;&gt;VPS服务提供商选择&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Amazon Web Service

&lt;ul&gt;
&lt;li&gt;大公司，服务稳定，无须担心亚马逊被封（因为亚马逊非常熟悉中国的那一套，&lt;a href=&#34;http://zhuanlan.zhihu.com/riobard/19910423&#34;&gt;有图&lt;/a&gt;为证）；&lt;/li&gt;
&lt;li&gt;高度可定制；&lt;/li&gt;
&lt;li&gt;丰富的文档、社区支持；&lt;/li&gt;
&lt;li&gt;按小时收费，新注册用户可以免费使用一年；&lt;/li&gt;
&lt;li&gt;可以将虚拟机部署在东京，理论上访问速度更快。&lt;/li&gt;
&lt;li&gt;缺点：&lt;strong&gt;设置复杂&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;DigitalOcean

&lt;ul&gt;
&lt;li&gt;可选择包月套餐，性价比更高；&lt;/li&gt;
&lt;li&gt;控制台界面清爽、简洁。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Linode 似乎很多人在用，一个老牌的VPS提供商，但是我没有用过。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果你选择 DigitalOcean，点击&lt;a href=&#34;https://www.digitalocean.com/?refcode=ba81ee4b40b2&#34;&gt;链接&lt;/a&gt;注册，可以获得10美元的优惠。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;参考文献:eb745fd234e99be994e6ebc392359fde&#34;&gt;参考文献：&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-setup-your-own-vpn-with-pptp&#34;&gt;How To Setup Your Own VPN With PPTP &amp;ndash; DigitalOcean.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://riobard.com/2011/11/12/pptp-vpn-on-ubuntu/&#34;&gt;Configure PPTP VPN on Ubuntu&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
          </item>
        
      
    
      
        
          <item>
            <title>在 AWS AutoScaling Group 中替换 Instance</title>
            <link>http://yumminhuang.github.io/blog/2014/08/02/%E5%9C%A8-aws-autoscaling-group-%E4%B8%AD%E6%9B%BF%E6%8D%A2-instance/</link>
            <pubDate>Sat, 02 Aug 2014 00:00:00 +0000</pubDate>
            
            <guid>http://yumminhuang.github.io/blog/2014/08/02/%E5%9C%A8-aws-autoscaling-group-%E4%B8%AD%E6%9B%BF%E6%8D%A2-instance/</guid>
            <description>&lt;p&gt;这两周，我被分配的任务是实现 &lt;a href=&#34;http://aws.amazon.com/&#34;&gt;AWS&lt;/a&gt; 的 &lt;a href=&#34;http://aws.amazon.com/autoscaling/&#34;&gt;Auto Scaling&lt;/a&gt;功能。多亏有了 &lt;a href=&#34;https://github.com/boto/boto&#34;&gt;Boto&lt;/a&gt;， 很快就实现了创建 Auto Scaling Group 和添加 Scaling Policy。但是有一个问题却花费了一些时间才顺利解决。&lt;/p&gt;

&lt;p&gt;我们的团队每周四发布新的代码。为了确保服务不中断，更新代码的步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;创建并配置（下载新发布的代码）多个新的 Instance；&lt;/li&gt;
&lt;li&gt;依次关闭旧的 Instance，每关闭一个 Instance，就激活（运行代码）一个新的 Instance 来替代被关闭的 Instance。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这样可以保证在 AWS 上运行的 Instance 依次得到更新，并且服务没有中断。&lt;/p&gt;

&lt;p&gt;现在的问题是：使用了 Auto Scaling 之后，每次尝试改变 Auto Scaling Group 当中的 Instance 数目，都会激发 Scaling Policy。比如我想关闭一个旧的 Instance，这样 Auto Scaling Group 当中 Instance 的数量就会小于 Desired Capacity，Auto Scaling Group 就会新创建一个 Instance， 而不是等我激活一个 Instance 去替代。&lt;/p&gt;

&lt;p&gt;我想到的办法步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将 Auto Scaling Group 挂起（避免激发 Scaling Policy）；&lt;/li&gt;
&lt;li&gt;按照以前的方法替换旧的 Instance；&lt;/li&gt;
&lt;li&gt;将新创建的 Instance 添加到 Auto Scaling Group。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为 AWS Auto Scaling 的特性（比如 Auto Scaling Group 被挂起的时候不能够添加 Instance，&lt;code&gt;desired_capacity&lt;/code&gt; 不能小于 &lt;code&gt;min_size&lt;/code&gt;），实现第三步并不容易。具体来说第三步又要分成下面几个步骤：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将 Auto Scaling Group 的 &lt;code&gt;desired_capacity&lt;/code&gt; 和 &lt;code&gt;min_size&lt;/code&gt; 分别置为 &lt;code&gt;0&lt;/code&gt;（防止恢复 Auto Scaling Group 的时候自动创建 Instance）；&lt;/li&gt;
&lt;li&gt;恢复 Auto Scaling Group（结束挂起状态，然后才可以添加 Instance）；&lt;/li&gt;
&lt;li&gt;添加 Instance 到 Auto Scaling Group 里；&lt;/li&gt;
&lt;li&gt;恢复 Auto Scaling Group 的 &lt;code&gt;min_size&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下面提供一份示例代码以供参考：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!python
import sys
import time

from boto.ec2.autoscale import AutoScaleConnection
from boto.ec2.connection import EC2Connection

AUTO_SCALING_GROUP = &amp;quot;test_auto_scaling_group&amp;quot;
NEW_INSTANCES = [&amp;quot;i-4acb0666&amp;quot;, &amp;quot;i-4acbqa9&amp;quot;]
CHECK_INTERVAL = 5


def suspend(as_conn):
    &amp;quot;&amp;quot;&amp;quot;
    Suspend auto scaling group
    &amp;quot;&amp;quot;&amp;quot;
    as_conn.suspend_processes(AUTO_SCALING_GROUP)
    print &amp;quot;Suspend Done\n&amp;quot;


def resume(as_conn):
    &amp;quot;&amp;quot;&amp;quot;
    Resume auto scaling group
    &amp;quot;&amp;quot;&amp;quot;
    as_conn.resume_processes(AUTO_SCALING_GROUP)
    print &amp;quot;Resume Done\n&amp;quot;


def get_instance_by_id(ec2conn, inst_id):
    &amp;quot;&amp;quot;&amp;quot;
    Get instance by its id
    &amp;quot;&amp;quot;&amp;quot;
    ...
    pass

def deactivate_instance(inst):
    &amp;quot;&amp;quot;&amp;quot;
    Deactivate instance
    &amp;quot;&amp;quot;&amp;quot;
    ...
    pass


def delete_instances(as_conn, ec2conn):
    &amp;quot;&amp;quot;&amp;quot;
    Delete instances in auto scaling group
    &amp;quot;&amp;quot;&amp;quot;
    as_group = as_conn.get_all_groups(names=[AUTO_SCALING_GROUP])[0]
    instances = [get_instance_by_id(ec2conn, i.instance_id) for i in as_group.instances]
    for instance in instances:
        if instance.state != &amp;quot;terminated&amp;quot;:
            print &amp;quot;*** Terminate Instance %s&amp;quot; % instance.id
            deactivate_instance(instance)
    # All instances should be terminated
    while any([inst.update() != &amp;quot;terminated&amp;quot; for inst in instances]):
        sys.stdout.write(&amp;quot;.&amp;quot;)
        sys.stdout.flush()
        time.sleep(CHECK_INTERVAL)
    print &amp;quot;.\nDelete Done\n&amp;quot;


def attach_instances(as_conn):
    &amp;quot;&amp;quot;&amp;quot;
    Attach instances into auto scaling group
    &amp;quot;&amp;quot;&amp;quot;
    while True and NEW_INSTANCES:
        as_group = as_conn.get_all_groups(names=[AUTO_SCALING_GROUP])[0]
        if len(as_group.instances) == 0:
            as_conn.attach_instances(AUTO_SCALING_GROUP, NEW_INSTANCES)
            print &amp;quot;Attach Done\n&amp;quot;
            return
        else:
            print &amp;quot;There are instances still in the group&amp;quot;
            time.sleep(CHECK_INTERVAL)


def set_capacity(as_conn):
    &amp;quot;&amp;quot;&amp;quot;
    Set desired capacity and minimum size as 0
    &amp;quot;&amp;quot;&amp;quot;
    as_group = as_conn.get_all_groups(names=[AUTO_SCALING_GROUP])[0]
    as_group.min_size = 0
    as_group.desired_capacity = 0
    as_group.update()
    print &amp;quot;Set Capacity Done\n&amp;quot;


def resume_capacity(as_conn):
    &amp;quot;&amp;quot;&amp;quot;
    Resume minimum size as the original value
    &amp;quot;&amp;quot;&amp;quot;
    as_group = as_conn.get_all_groups(names=[AUTO_SCALING_GROUP])[0]
    setattr(as_group,&amp;quot;min_size&amp;quot;, 1)
    as_group.update()
    print &amp;quot;Resume Capacity Done\n&amp;quot;


def main():
    as_conn = AutoScaleConnection()
    ec2conn = EC2Connection()

    print &amp;quot;Suspend Auto Scaling Group&amp;quot;
    suspend(as_conn)

    print &amp;quot;Delete Instances&amp;quot;
    delete_instances(as_conn, ec2conn)

    print &amp;quot;Set Capacity&amp;quot;
    set_capacity(as_conn)

    print &amp;quot;Resume Auto Scaling Group&amp;quot;
    resume(as_conn)

    print &amp;quot;Attach Instances&amp;quot;
    attach_instances(as_conn)

    print &amp;quot;Resume Capacity&amp;quot;
    resume_capacity(as_conn)


if __name__ == &amp;quot;__main__&amp;quot;:
    main()
&lt;/code&gt;&lt;/pre&gt;
</description>
          </item>
        
      
    
  </channel>
</rss>
